[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python for Clinical Study Reports and Submission",
    "section": "",
    "text": "Welcome\nWelcome to Python for Clinical Study Reports and Submission. Clinical study reports (CSR) are crucial components in clinical trial development. A CSR is an “integrated” full scientific report of an individual clinical trial.\nThe ICH E3: Structure and Content of Clinical Study Reports offers comprehensive instructions to sponsors on the creation of a CSR. This book is a clear and straightforward guide on using Python to streamline the process of preparing CSRs. Additionally, it provides detailed guidance on the submission process to regulatory agencies. Whether you are a beginner or an experienced developer, this book is an indispensable asset in your clinical reporting toolkit.\nThis is a work-in-progress draft.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#events",
    "href": "index.html#events",
    "title": "Python for Clinical Study Reports and Submission",
    "section": "Events",
    "text": "Events\n\n\n\nVenue\nType\nDate\nMaterials\n\n\n\n\nR/Pharma Conference\nWorkshop\n2025-11-07\nSlides",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "In this book\nThis book is designed for people who are interested in using Python for clinical development. Each part of the book makes certain assumptions about the readers’ background:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#in-this-book",
    "href": "preface.html#in-this-book",
    "title": "Preface",
    "section": "",
    "text": "Part 1, titled “Environment and toolchain” and “Reporting packages”, provides general information on setting up Python development environments for clinical reporting.\nPart 2, titled “Delivering TLFs in CSR”, provides general information and examples on creating tables, listings, and figures using Python. It assumes that readers are individual contributors to a clinical project with prior experience in Python. Familiarity with data manipulation using Polars is expected. Recommended references for this part include Python Polars: The Definitive Guide, theand the rtflite documentation.\nPart 3, titled “Clinical trial project”, provides general information and examples on managing a clinical trial A&R project using Python. It assumes that readers are project leads who have experience in Python package development.\nPart 4, titled “eCTD submission package”, provides general information on preparing submission packages related to the CSR in the electronic Common Technical Document (eCTD) format using Python. It assumes that readers are project leads of clinical projects who possess experience in Python package development and regulatory submission processes.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#philosophy",
    "href": "preface.html#philosophy",
    "title": "Preface",
    "section": "Philosophy",
    "text": "Philosophy\nWe share the same philosophy described in the introduction of the R Packages book (Wickham and Bryan 2023), which we quote below:\n\n“Anything that can be automated, should be automated.”\n“Do as little as possible by hand. Do as much as possible with functions.”",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#authors-and-contributors",
    "href": "preface.html#authors-and-contributors",
    "title": "Preface",
    "section": "Authors and contributors",
    "text": "Authors and contributors\nThis document is a collaborative effort maintained by a community. As you read through it, you also have the opportunity to contribute and enhance its quality. Your input and involvement play a vital role in shaping the excellence of this document.\n\nAuthors: made significant contributions to at least one chapter, constituting the majority of the content.\nYilong Zhang, Nan Xiao,\n\n\n\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. R Packages. O’Reilly Media, Inc.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "env-dev.html",
    "href": "env-dev.html",
    "title": "1  Python developer setup",
    "section": "",
    "text": "1.1 Development environments\nFor this book, you have several options for your development environment. Choose the one that best fits your current setup and constraints.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Python developer setup</span>"
    ]
  },
  {
    "objectID": "env-dev.html#development-environments",
    "href": "env-dev.html#development-environments",
    "title": "1  Python developer setup",
    "section": "",
    "text": "1.1.1 GitHub Codespaces\nGitHub Codespaces provides a cloud-based development environment with everything pre-configured. This is the easiest option if you don’t have a local Python setup.\nWe will provide a dev container configuration that includes:\n\nPython with uv pre-installed.\nAll necessary VS Code extensions.\nConsistent environment across all readers, useable in the web browser.\n\nTo use Codespaces, simply click the “Code” button in the repository and select “Create codespace on main”.\n\n\n\n\n\n\nNote\n\n\n\nCodespaces currently offers 120 hours of free compute time per month for personal accounts. This is more than sufficient for this book.\n\n\n\n\n1.1.2 Positron\nPositron is Posit’s next-generation data science IDE, built on Code OSS (the open source core of VS Code), with specific improvements for R and Python development.\nKey features for Python work:\n\nNative notebook support.\nInteractive variable explorer.\nIntegrated plot viewer.\nBuilt-in data viewer for DataFrames.\n\n\n\nPositron uses Open VSX instead of the Microsoft VS Code marketplace. Most essential Python extensions are available, but the selection is more limited.\nDownload Positron from https://positron.posit.co/.\n\n\n1.1.3 VS Code\nVisual Studio Code remains the most popular choice for Python development. It offers a rich ecosystem of extensions and tools.\nEssential extensions for this book:\n\nPython: Core Python language support.\nPylance: Fast, feature-rich Python language server.\nRuff: Lightning-fast linting and formatting.\nEven Better TOML: Syntax highlighting for TOML files (pyproject.toml).\nQuarto: Authoring support for Quarto documents.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Python developer setup</span>"
    ]
  },
  {
    "objectID": "env-dev.html#vs-code-settings",
    "href": "env-dev.html#vs-code-settings",
    "title": "1  Python developer setup",
    "section": "1.2 VS Code settings",
    "text": "1.2 VS Code settings\n\n1.2.1 Unicode highlighting\nPython allows Unicode characters in strings and identifiers. AI coding tools might also generate code with non-ASCII characters. For regulatory work, you should highlight non-ASCII characters to find these hidden issues early and avoid problems in submissions.\nVia Settings UI:\n\nOpen Command Palette (Cmd/Ctrl + Shift + P)\nSearch for “Preferences: Open Settings (UI)”\nSearch for “Unicode Highlight”\nEnable “Non Basic ASCII” for both trusted and untrusted workspaces\n\nVia Settings JSON:\nOpen Command Palette with Cmd/Ctrl + Shift + P, select “Preferences: Open User Settings (JSON)”, then add:\n\"editor.unicodeHighlight.nonBasicASCII\": true\nThis highlights characters like curly quotes, em dashes, and other non-ASCII characters that could cause issues in eCTD submission packages.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Python developer setup</span>"
    ]
  },
  {
    "objectID": "env-dev.html#terminal-setup",
    "href": "env-dev.html#terminal-setup",
    "title": "1  Python developer setup",
    "section": "1.3 Terminal setup",
    "text": "1.3 Terminal setup\nFor local development, you will interact with uv and Quarto through the terminal.\n\n1.3.1 Shell\nAny modern shell works well:\n\nmacOS/Linux: zsh (default on macOS), bash\nWindows: PowerShell, Windows Terminal\n\n\n\n1.3.2 Terminal emulator\nIf you are on macOS and want a faster terminal experience, consider Ghostty. It is written in Zig for exceptional performance.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Python developer setup</span>"
    ]
  },
  {
    "objectID": "env-dev.html#ai-coding-assistants",
    "href": "env-dev.html#ai-coding-assistants",
    "title": "1  Python developer setup",
    "section": "1.4 AI coding assistants",
    "text": "1.4 AI coding assistants\nModern agentic AI coding tools can accelerate statistical and clinical coding tasks, especially for popular programming languages like Python. We encourage you to use them, for example:\n\nCodex (command-line interface, VS Code extension)\nClaude Code (command-line interface)\nCursor (AI-first editor)\nGitHub Copilot (VS Code extension)\n\n\n1.4.1 Effective use of AI tools\nTo use AI assistants effectively for programming, you need:\nProduct manager mindset: Know exactly what you want to build. In clinical reporting, this means understanding the table shell, statistical method, and regulatory requirements.\nSoftware architect mindset: Evaluate model outputs critically. Can you spot issues with data transformations? Do the statistical computations match the statistical analysis plan? Is the output format submission-ready?\n\n\n\n\n\n\nWarning\n\n\n\nAI tools are assistants, not replacements for domain expertise. Always verify outputs against statistical analysis plans and regulatory guidance.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Python developer setup</span>"
    ]
  },
  {
    "objectID": "env-dev.html#whats-next",
    "href": "env-dev.html#whats-next",
    "title": "1  Python developer setup",
    "section": "1.5 What’s next",
    "text": "1.5 What’s next\nWith your development environment configured, you are ready to learn about uv, the modern project management tool for Python.\nIn the next chapter, we will cover:\n\nCreating and managing Python projects.\nPinning Python versions.\nInstalling dependencies.\nUnderstanding the modern Python packaging ecosystem.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Python developer setup</span>"
    ]
  },
  {
    "objectID": "env-uv.html",
    "href": "env-uv.html",
    "title": "2  Python projects with uv",
    "section": "",
    "text": "2.1 Why virtual environments\nIn Python, virtual environments are not optional. They are essential for any serious project work.\nUnlike R’s renv (which primarily helps with reproducibility), Python virtual environments serve a fundamental purpose: isolating project dependencies from the system Python.\nHere is why this matters:",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#why-virtual-environments",
    "href": "env-uv.html#why-virtual-environments",
    "title": "2  Python projects with uv",
    "section": "",
    "text": "Different projects need different package versions.\nSystem Python library should never be modified directly.\nDependency conflicts are common and destructive.\nReproducibility requires exact version control.\n\n\n\n\n\n\n\nWarning\n\n\n\nInstalling packages globally with pip install without a virtual environment will cause conflicts and break system tools. Always use virtual environments. To install Python packages as global command-line tools, use pipx.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#what-is-uv",
    "href": "env-uv.html#what-is-uv",
    "title": "2  Python projects with uv",
    "section": "2.2 What is uv",
    "text": "2.2 What is uv\nuv is a modern Python package and project manager written in Rust. It replaces and improves upon a scattered toolchain:\n\npip (package installation)\nvenv (virtual environment creation)\npyenv (Python version management)\npip-tools (dependency locking)\nsetuptools (package building)\n\nBenefits of uv:\n\nFast: 10-100x faster than pip due to Rust implementation.\nComplete: Manages Python versions, dependencies, and builds.\nModern: Uses pyproject.toml as the single source of truth.\nReliable: Automatic dependency resolution and lock files.\n\n\n\nIn R terms, uv combines functionality from renv, devtools, usethis, and pak into a single, cohesive tool.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#python-packaging-standards",
    "href": "env-uv.html#python-packaging-standards",
    "title": "2  Python projects with uv",
    "section": "2.3 Python packaging standards",
    "text": "2.3 Python packaging standards\nPython has standardized on pyproject.toml as the configuration file for all projects. This is similar to R’s DESCRIPTION file but uses TOML format.\nThe Official Python packaging guide is available at https://packaging.python.org/.\nKey concepts:\n\npyproject.toml defines project metadata and dependencies.\nuv.lock records exact versions (like renv.lock).\nBuild backends (like hatchling) create distributable packages.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#installing-uv",
    "href": "env-uv.html#installing-uv",
    "title": "2  Python projects with uv",
    "section": "2.4 Installing uv",
    "text": "2.4 Installing uv\nFollow the official installation guide.\nmacOS and Linux:\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nWindows:\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\nVia Homebrew (macOS):\nbrew install uv\nVerify installation:\nuv --version",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#updating-uv",
    "href": "env-uv.html#updating-uv",
    "title": "2  Python projects with uv",
    "section": "2.5 Updating uv",
    "text": "2.5 Updating uv\nuv can update itself:\nuv self update\nRegular updates are important because uv frequently adds support for new Python versions and features.\n\n\n\n\n\n\nNote\n\n\n\nuv uses Python distributions from the python-build-standalone project. These are optimized, portable Python builds that work consistently across platforms.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#initialize-a-project",
    "href": "env-uv.html#initialize-a-project",
    "title": "2  Python projects with uv",
    "section": "2.6 Initialize a project",
    "text": "2.6 Initialize a project\nCreate a new Python project:\nuv init pycsr-example\ncd pycsr-example\nThis creates a basic structure:\npycsr-example/\n├── .python-version    # Pinned Python version\n├── pyproject.toml     # Project metadata and dependencies\n├── README.md          # Project documentation\n└── src/\n    └── pycsr_example/\n        └── __init__.py\n\n\nNotice the directory name uses hyphens (pycsr-example) while the package name uses underscores (pycsr_example). This is Python convention.\n\n2.6.1 Project structure\nThe pyproject.toml file contains project configuration:\n[project]\nname = \"pycsr-example\"\nversion = \"0.1.0\"\ndescription = \"Example clinical study report project\"\ndependencies = []\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\nKey sections:\n\n[project]: Package metadata.\n[project.dependencies]: Hard, runtime dependencies.\n[dependency-groups.dev]: Development dependencies.\n[build-system]: How to build the package.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#pin-python-version",
    "href": "env-uv.html#pin-python-version",
    "title": "2  Python projects with uv",
    "section": "2.7 Pin Python version",
    "text": "2.7 Pin Python version\nSpecify the exact Python version for your project:\nuv python pin 3.13.9\nThis updates .python-version file so everyone uses the same Python version when they restore the environment.\n\n\n\n\n\n\nImportant\n\n\n\nUse the full MAJOR.MINOR.PATCH version (for example, 3.13.9) rather than just MAJOR.MINOR (for example, 3.13). This prevents drift as new patch versions are released.\n\n\nWhy pin the exact version:\n\nPatch releases can introduce subtle behavior changes.\nReproducibility requires exact version matching.\nRegulatory submissions should document the exact Python version.\n\nCheck which Python versions are available:\nuv python list\nInstall a specific Python version if needed:\nuv python install 3.13.9",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#managing-dependencies",
    "href": "env-uv.html#managing-dependencies",
    "title": "2  Python projects with uv",
    "section": "2.8 Managing dependencies",
    "text": "2.8 Managing dependencies\n\n2.8.1 Adding dependencies\nAdd runtime dependencies:\nuv add polars plotnine rtflite\nAdd development-only dependencies:\nuv add --dev ruff pytest mypy\nThis updates pyproject.toml:\n[project]\ndependencies = [\n    \"polars&gt;=1.34.0\",\n    \"plotnine&gt;=0.15.0\",\n    \"rtflite&gt;=1.0.2\",\n]\n\n[dependency-groups.dev]\ndependencies = [\n    \"ruff&gt;=0.14.1\",\n    \"pytest&gt;=8.4.2\",\n    \"mypy&gt;=1.18.2\",\n]\n\n\n\n\n\n\nNote\n\n\n\nBy default, uv adds dependencies with &gt;= constraints. This allows updates within compatible versions. The lock file ensures exact versions are used.\n\n\n\n\n2.8.2 Removing dependencies\nRemove a package:\nuv remove pandas\nThis removes the package from both pyproject.toml and the environment.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#lock-files-and-syncing",
    "href": "env-uv.html#lock-files-and-syncing",
    "title": "2  Python projects with uv",
    "section": "2.9 Lock files and syncing",
    "text": "2.9 Lock files and syncing\n\n2.9.1 Creating and updating the lock file\nGenerate or update the lock file:\nuv sync\nThis creates uv.lock, which records:\n\nExact version of every package.\nAll transitive dependencies.\nPackage hashes for verification.\n\nThe lock file ensures reproducibility across different machines and over time.\n\n\n2.9.2 Upgrading dependencies\nTo update packages while respecting constraints in pyproject.toml:\nuv lock --upgrade\nThen synchronize the environment:\nuv sync\nThis is similar to:\n\nR: renv::update() followed by renv::snapshot().\nNode.js: npm update followed by npm install.\n\n\n\nThe two-step process (lock & sync) gives you control: you can review lock file changes before updating your environment.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#running-commands",
    "href": "env-uv.html#running-commands",
    "title": "2  Python projects with uv",
    "section": "2.10 Running commands",
    "text": "2.10 Running commands\nYou have two options for running commands in your project environment.\n\n2.10.1 Option 1: Activate the virtual environment\nsource .venv/bin/activate  # macOS/Linux\n# or\n.venv\\Scripts\\activate     # Windows\nThen run commands directly:\npython -m pycsr_example\npytest\nruff check\nDeactivate when done:\ndeactivate\n\n\n2.10.2 Option 2: Use uv run\nRun commands without activation:\nuv run python -m pycsr_example\nuv run pytest\nuv run ruff check\n\n\n\n\n\n\nTip\n\n\n\nuv run is convenient for one-off commands and CI/CD scripts. For interactive work, activating the environment is often more ergonomic.\n\n\n\n\n2.10.3 uv run and uvx\nuvx runs tools in isolated, temporary environments:\nuvx ruff check .\nuvx black --check .\nUse uvx when:\n\nRunning tools you don’t want to install in the project.\nTrying packages without adding them as dependencies.\nRunning scripts that declare their own dependencies.\n\nUse uv run when:\n\nRunning project code.\nRunning tests.\nUsing project dependencies.\n\nSee using tools in uv for details.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#building-and-publishing",
    "href": "env-uv.html#building-and-publishing",
    "title": "2  Python projects with uv",
    "section": "2.11 Building and publishing",
    "text": "2.11 Building and publishing\nFor creating distributable packages, you need a build backend. The simplest option is hatchling.\nAdd to pyproject.toml:\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n2.11.1 Build wheel\nCreate distribution files:\nuv build\nThis creates: - dist/pycsr_example-0.1.0.tar.gz (source distribution) - dist/pycsr_example-0.1.0-py3-none-any.whl (wheel)\n\n\n2.11.2 Publish to PyPI\nPublish to the Python Package Index:\nuv publish\n\n\n\n\n\n\nNote\n\n\n\nBuilding and publishing are not typically needed for internal clinical reporting projects. However, if you develop reusable tools like table generation packages, open sourcing in a GitHub repository and publishing on PyPI will make them more visible.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#exercise",
    "href": "env-uv.html#exercise",
    "title": "2  Python projects with uv",
    "section": "2.12 Exercise",
    "text": "2.12 Exercise\nCreate a small project to practice uv commands:\n\nInitialize a new project called csr-practice.\nPin Python to version 3.13.9 (or latest available).\nAdd polars as a dependency.\nAdd pytest as a development dependency.\nExamine the generated pyproject.toml and uv.lock files.\nRun Python using uv run python --version.\n\n\n\nView solution\n\n# Initialize project\nuv init csr-practice\ncd csr-practice\n\n# Pin Python version\nuv python pin 3.13.9\n\n# Add dependencies\nuv add polars\nuv add --dev pytest\n\n# View configuration\ncat pyproject.toml\n\n# Check lock file\ncat uv.lock\n\n# Run Python\nuv run python --version\nYour pyproject.toml should look similar to:\n[project]\nname = \"csr-practice\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\ndependencies = [\n    \"polars&gt;=1.18.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=8.3.4\",\n]\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-uv.html#whats-next",
    "href": "env-uv.html#whats-next",
    "title": "2  Python projects with uv",
    "section": "2.13 What’s next",
    "text": "2.13 What’s next\nNow that you understand uv basics, the next chapter covers the Python package toolchain:\n\nFormatting and linting with Ruff.\nType checking with mypy.\nTesting with pytest.\nDocumentation generation.\nDevelopment workflows for clinical reporting.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python projects with uv</span>"
    ]
  },
  {
    "objectID": "env-pkg.html",
    "href": "env-pkg.html",
    "title": "3  Python package toolchain",
    "section": "",
    "text": "3.1 The modern Python toolchain\nIn R, packages like devtools, usethis, styler, lintr, and testthat provide development infrastructure. Python’s ecosystem distributes these functions across specialized tools.\nFor clinical reporting projects, we recommend:\nAll tools are installed as development dependencies and configured through pyproject.toml.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#the-modern-python-toolchain",
    "href": "env-pkg.html#the-modern-python-toolchain",
    "title": "3  Python package toolchain",
    "section": "",
    "text": "uv: Package and environment management.\nRuff: Code formatting and linting.\nmypy: Static type checking.\npytest: Unit testing framework.\nquartodoc: Documentation and reporting.\n\n\n\nFor R users, think of this as: uv = renv + pak + devtools, Ruff = styler + lintr, pytest = testthat, mypy = (no direct R equivalent).",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#ruff-formatting-and-linting",
    "href": "env-pkg.html#ruff-formatting-and-linting",
    "title": "3  Python package toolchain",
    "section": "3.2 Ruff: Formatting and linting",
    "text": "3.2 Ruff: Formatting and linting\nRuff is an super fast linter and formatter written in Rust. It replaces multiple legacy tools (Black, isort, Flake8, pyupgrade) with a single, consistent interface.\n\n3.2.1 Installation\nAdd Ruff as a development dependency:\nuv add --dev ruff\n\n\n3.2.2 Code formatting\nFormat your code:\nuv run ruff format\nOr using uvx:\nuvx ruff format\nRuff format:\n\nEnforces consistent style (like Black).\nSorts imports automatically.\nRemoves trailing whitespace.\nEnsures consistent line lengths.\n\n\n\n3.2.3 Linting\nCheck for linting issues:\nuv run ruff check\nFix auto-fixable issues:\nuv run ruff check --fix\nRuff detects:\n\nUnused imports and variables.\nUndefined names.\nStyle violations.\nCommon anti-patterns.\nSecurity issues.\n\n\n\n3.2.4 Configuration\nAdd Ruff configuration to pyproject.toml:\n[tool.ruff]\nline-length = 88\ntarget-version = \"py313\"\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\n\n[tool.ruff.lint]\nselect = [\n    \"E\",    # pycodestyle\n    \"F\",    # Pyflakes\n    \"UP\",   # pyupgrade\n    \"B\",    # flake8-bugbear\n    \"SIM\",  # flake8-simplify\n    \"I\",    # isort\n]\nignore = []\n\n\n\n\n\n\nNote\n\n\n\nLine length of 88 characters is the Python community standard. It balances readability with modern screen sizes.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#type-checking-with-mypy",
    "href": "env-pkg.html#type-checking-with-mypy",
    "title": "3  Python package toolchain",
    "section": "3.3 Type checking with mypy",
    "text": "3.3 Type checking with mypy\nPython supports optional type annotations through PEP 484. Type annotations improve code clarity and catch errors before runtime.\n\n3.3.1 Why type checking matters\nFor clinical programming:\n\nCatch data transformation errors at development time.\nDocument expected DataFrame structures.\nImprove IDE autocomplete and refactoring.\nReduce runtime errors in production.\n\n\n\n3.3.2 Installation\nAdd mypy as a development dependency:\nuv add --dev mypy\n\n\n3.3.3 Basic usage\nCheck types in your code:\nuv run mypy .\n\n\n3.3.4 Type annotation example\nWithout types:\ndef calculate_bmi(weight, height):\n    return weight / (height ** 2)\nWith types:\ndef calculate_bmi(weight: float, height: float) -&gt; float:\n    \"\"\"Calculate BMI from weight (kg) and height (m).\"\"\"\n    return weight / (height ** 2)\nThe type checker verifies:\n\nArguments are the correct type.\nReturn value matches the declared type.\nOperations are valid for the types used.\n\n\n\n3.3.5 Configuration\nAdd mypy settings to pyproject.toml:\n[tool.mypy]\npython_version = \"3.13\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = false\ndisallow_incomplete_defs = true\ncheck_untyped_defs = true\nno_implicit_optional = true\n\n\nStart with lenient settings (disallow_untyped_defs = false) and progressively tighten as you add type annotations to your codebase.\n\n\n3.3.6 Type stubs for libraries\nSome libraries don’t include type information. Install type stubs when available:\nuv add --dev types-tabulate\n\n\n\n\n\n\nNote\n\n\n\nPopular data science libraries like polars include built-in type annotations. Older libraries like pandas require separate stub packages (pandas-stubs).",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#testing-with-pytest",
    "href": "env-pkg.html#testing-with-pytest",
    "title": "3  Python package toolchain",
    "section": "3.4 Testing with pytest",
    "text": "3.4 Testing with pytest\npytest is Python’s de facto standard testing framework. It’s more powerful and ergonomic than the built-in unittest module.\n\n3.4.1 Installation\nAdd pytest and coverage tools:\nuv add --dev pytest pytest-cov\n\n\n3.4.2 Writing tests\nCreate a tests/ directory:\npycsr-example/\n├── src/\n│   └── pycsr_example/\n│       └── __init__.py\n└── tests/\n    └── test_calculations.py\nWrite a simple test in tests/test_calculations.py:\nfrom pycsr_example.calculations import calculate_bmi\nimport pytest\n\ndef test_calculate_bmi():\n    # Normal BMI calculation\n    assert calculate_bmi(70, 1.75) == pytest.approx(22.857142857142858)\n\ndef test_calculate_bmi_underweight():\n    # BMI &lt; 18.5 indicates underweight\n    assert calculate_bmi(50, 1.75) &lt; 18.5\n\n\n3.4.3 Running tests\nRun all tests:\nuv run pytest\nRun with verbose output:\nuv run pytest -v\nRun specific test file:\nuv run pytest tests/test_calculations.py\n\n\n3.4.4 Code coverage\nGenerate coverage report:\nuv run pytest --cov=pycsr_example --cov-report=term\nGenerate HTML coverage report:\nuv run pytest --cov=pycsr_example --cov-report=html\nThis creates htmlcov/index.html showing which lines are tested.\n\n\n\n\n\n\nImportant\n\n\n\nFor regulatory submissions, high test coverage demonstrates code quality. Aim for &gt;80% coverage for critical data transformation and statistical computation functions.\n\n\n\n\n3.4.5 pytest configuration\nAdd pytest settings to pyproject.toml:\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\npython_functions = [\"test_*\"]\naddopts = [\n    \"--strict-markers\",\n    \"--strict-config\",\n    \"-ra\",\n]",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#documentation-generation",
    "href": "env-pkg.html#documentation-generation",
    "title": "3  Python package toolchain",
    "section": "3.5 Documentation generation",
    "text": "3.5 Documentation generation\nFor clinical reporting projects, documentation serves two purposes:\n\nCode documentation: Function and module documentation.\nReport generation: Analysis reports and TLFs.\n\n\n3.5.1 Quarto for reports\nWe use Quarto for creating reproducible analysis documents:\n# Install Quarto separately (not via uv)\n# See: https://quarto.org/docs/get-started/\nQuarto documents (.qmd files) combine:\n\nMarkdown text.\nPython code cells.\nGenerated outputs (tables, listings, figures).\n\nThis book itself is written in Quarto.\n\n\n3.5.2 quartodoc for API documentation\nFor packages that need API documentation (similar to R’s pkgdown), use quartodoc:\nuv add --dev quartodoc\nquartodoc generates documentation from docstrings and integrates with Quarto for full website generation.\n\n\nFor analysis projects (rather than reusable packages), Quarto alone is usually sufficient. Use quartodoc when building analysis packages for team to collaborate on.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#development-workflow",
    "href": "env-pkg.html#development-workflow",
    "title": "3  Python package toolchain",
    "section": "3.6 Development workflow",
    "text": "3.6 Development workflow\nPutting it all together, a typical development cycle looks like:\n\nFormat code: uv run ruff format\nCheck linting: uv run ruff check --fix\nVerify types: uv run mypy .\nRun tests: uv run pytest --cov=pycsr_example\nGenerate reports: quarto render\n\n\n3.6.1 Pre-commit automation\nYou can automate these checks using Git hooks (not covered in this book), but manual execution provides better learning and control during development.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#clinical-project-structure-guidelines",
    "href": "env-pkg.html#clinical-project-structure-guidelines",
    "title": "3  Python package toolchain",
    "section": "3.7 Clinical project structure guidelines",
    "text": "3.7 Clinical project structure guidelines\nIn case you need clinical reporting projects using both R and Python:\nSeparate R and Python directories:\nproject/\n├── r-package/          # R package for R-based analyses\n│   ├── DESCRIPTION\n│   ├── R/\n│   └── tests/\n├── python-package/     # Python package for Python-based analyses\n│   ├── pyproject.toml\n│   ├── src/\n│   └── tests/\n├── data/               # Shared input data (SDTM, ADaM)\n└── output/             # Shared output (TLFs, reports)\nWhy separate?\nAs John Carmack noted: “It’s almost always a mistake to mix languages in a single project.”\nReasons:\n\nDifferent build systems.\nDifferent dependency management.\nDifferent testing frameworks.\nDifferent IDE configurations.\n\nShared resources:\n\nInput datasets (SDTM, ADaM) can be in a common data/ directory.\nOutput deliverables can go to a common output/ directory.\nDocumentation can reference both implementations.\n\n\n\n\n\n\n\nNote\n\n\n\nFor this book, we focus exclusively on Python. Mixed R/Python workflows are beyond scope but follow the same principles.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#exercise",
    "href": "env-pkg.html#exercise",
    "title": "3  Python package toolchain",
    "section": "3.8 Exercise",
    "text": "3.8 Exercise\nSet up a complete development environment:\n\nCreate a new project with uv init dev-practice.\nAdd development dependencies: ruff, mypy, pytest, pytest-cov.\nCreate a simple function in src/dev_practice/stats.py:\ndef mean(values: list[float]) -&gt; float:\n    return sum(values) / len(values)\nWrite a test in tests/test_stats.py.\nRun Ruff format and check.\nRun mypy type checking.\nRun pytest with coverage.\n\n\n\nView solution\n\n# Create project\nuv init dev-practice\ncd dev-practice\n\n# Add dev dependencies\nuv add --dev ruff mypy pytest pytest-cov\n\n# Create stats module\nmkdir -p src/dev_practice\ncat &gt; src/dev_practice/stats.py &lt;&lt; 'EOF'\ndef mean(values: list[float]) -&gt; float:\n    \"\"\"Calculate the arithmetic mean of a list of numbers.\"\"\"\n    if not values:\n        raise ValueError(\"Cannot calculate mean of empty list\")\n    return sum(values) / len(values)\nEOF\n\n# Create test file\nmkdir -p tests\ncat &gt; tests/test_stats.py &lt;&lt; 'EOF'\nimport pytest\nfrom dev_practice.stats import mean\n\ndef test_mean_basic():\n    assert mean([1.0, 2.0, 3.0]) == 2.0\n\ndef test_mean_single_value():\n    assert mean([5.0]) == 5.0\n\ndef test_mean_empty_raises():\n    with pytest.raises(ValueError):\n        mean([])\nEOF\n\n# Run checks\nuv run ruff format .\nuv run ruff check .\nuv run mypy src/\nuv run pytest --cov=dev_practice --cov-report=term\nExpected output from pytest:\n============================= test session starts ==============================\ncollected 3 items\n\ntests/test_stats.py ...                                                  [100%]\n\n---------- coverage: platform darwin, python 3.13.9-final-0 ----------\nName                        Stmts   Miss  Cover\n-----------------------------------------------\nsrc/dev_practice/__init__.py    0      0   100%\nsrc/dev_practice/stats.py       4      0   100%\n-----------------------------------------------\nTOTAL                           4      0   100%\n\n============================== 3 passed in 0.05s ===============================",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#example-repositories",
    "href": "env-pkg.html#example-repositories",
    "title": "3  Python package toolchain",
    "section": "3.9 Example repositories",
    "text": "3.9 Example repositories\nDemo project repositories have been created:\n\nPython package example: [Link to be added]\neCTD package example: [Link to be added]\n\nWith the knowledge from this chapter, you can understand how these projects are organized and develop similar professional Python packages for clinical reporting.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "env-pkg.html#whats-next",
    "href": "env-pkg.html#whats-next",
    "title": "3  Python package toolchain",
    "section": "3.10 What’s next",
    "text": "3.10 What’s next\nYou now have a complete Python development environment with:\n\nuv for project and dependency management.\nRuff for code quality.\nmypy for type safety.\npytest for testing.\nQuarto for documentation.\n\nNext part will introduce how to create real clinical study reports, demonstrating TLF generation with polars and rtflite.",
    "crumbs": [
      "Environment and toolchain",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python package toolchain</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html",
    "href": "tlf-overview.html",
    "title": "4  TLF overview",
    "section": "",
    "text": "4.1 Overview\nTables, listings, and figures (TLFs) are essential components of clinical study reports (CSRs) and regulatory submissions. Following ICH E3 guidance, TLFs provide standardized summaries of clinical trial data that support regulatory decision-making.\nThis chapter provides an overview of creating TLFs using Python, focusing on the tools and workflows demonstrated throughout this book.",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#background",
    "href": "tlf-overview.html#background",
    "title": "4  TLF overview",
    "section": "4.2 Background",
    "text": "4.2 Background\nSubmitting clinical trial results to regulatory agencies is a crucial aspect of clinical development. The Electronic Common Technical Document (eCTD) has emerged as the global standard format for regulatory submissions. For instance, the United States Food and Drug Administration (US FDA) mandates the use of eCTD for new drug applications and biologics license applications.\nA CSR provides comprehensive information about the methods and results of an individual clinical study. To support the statistical analysis, numerous tables, listings, and figures are included within the main text and appendices. The creation of CSR is a collaborative effort that involves various professionals such as clinicians, medical writers, statisticians, and statistical programmers.\nWithin an organization, these professionals typically collaborate to define, develop, validate, and deliver the necessary TLFs for a CSR. These TLFs serve to summarize the efficacy and/or safety of the pharmaceutical product under study. In the pharmaceutical industry, Microsoft Word is widely utilized for CSR preparation. As a result, the deliverables from statisticians and statistical programmers are commonly provided in formats such as .rtf, .doc, .docx to align with industry standards and requirements.\n\n\n\n\n\n\nNote\n\n\n\nEach organization may define specific TLF format requirements that differ from the examples in this book. It is advisable to consult and adhere to the guidelines and specifications set by your respective organization when preparing TLFs for submission.\n\n\nBy following the ICH E3 guidance, most TLFs in a CSR are located at:\n\nSection 10: Study participants\nSection 11: Efficacy evaluation\nSection 12: Safety evaluation\nSection 14: Tables, listings, and figures referrals but not included in the text\nSection 16: Appendices",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#datasets",
    "href": "tlf-overview.html#datasets",
    "title": "4  TLF overview",
    "section": "4.3 Datasets",
    "text": "4.3 Datasets\nThe dataset structure follows CDISC Analysis Data Model (ADaM).\nIn this project, we use publicly available CDISC pilot study data, which is accessible through the CDISC GitHub repository.\nWe have converted these datasets from the .xpt format to the .parquet format for ease of use and compatibility with Python tools. The dataset structure adheres to the CDISC Analysis Data Model (ADaM) standard.",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#tools",
    "href": "tlf-overview.html#tools",
    "title": "4  TLF overview",
    "section": "4.4 Tools",
    "text": "4.4 Tools\nTo exemplify the generation of TLFs in RTF format, we rely on the functionality provided by two Python packages:\n\nPolars: preparation of datasets in a format suitable for reporting purposes. Polars offers a comprehensive suite of tools and functions for data manipulation and transformation, ensuring that the data is structured appropriately.\nrtflite: creation of RTF files. The rtflite package offers functions specifically designed for generating RTF files, allowing us to produce TLFs in the desired format.",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#polars",
    "href": "tlf-overview.html#polars",
    "title": "4  TLF overview",
    "section": "4.5 Polars",
    "text": "4.5 Polars\nPolars is an open-source library for data manipulation implemented in Rust with Python bindings. It offers exceptional performance while maintaining a user-friendly interface for interactive data analysis.\nKey advantages of Polars include:\n\nPerformance: 10-100x faster than pandas for most operations due to Rust implementation\nMemory efficiency: Lazy evaluation and columnar storage reduce memory usage\nFamiliar syntax: Similar to tidyverse-style pipelines, making it accessible to R users\nType safety: Strong typing system that catches errors early in development\n\nThe creators of Polars have provided exceptional documentation and tutorials that serve as valuable resources for learning and mastering the functionalities of the library.\nFurthermore, there are several books available that serve as introductions to Polars:\n\nPython Polars: The Definitive Guide\n\n\n\n\n\n\n\nNote\n\n\n\nIn this book, we assume that the reader has some experience with data manipulation concepts. This prior knowledge enables a more efficient and focused exploration of the clinical reporting concepts presented throughout the book.\n\n\nTo illustrate the basic usage of Polars, let’s work with a sample ADSL dataset. This dataset contains subject-level information from a clinical trial, which will serve as a practical example for generating summaries using Polars.\n\nimport polars as pl\n\n# Read clinical data\nadsl = pl.read_parquet(\"data/adsl.parquet\")\n\n# Select columns \nadsl = adsl.select([\"USUBJID\", \"TRT01A\", \"AGE\", \"SEX\"])\n\n# Basic data exploration\nadsl.head()\n\n\nshape: (5, 4)\n\n\n\nUSUBJID\nTRT01A\nAGE\nSEX\n\n\nstr\nstr\nf64\nstr\n\n\n\n\n\"01-701-1015\"\n\"Placebo\"\n63.0\n\"Female\"\n\n\n\"01-701-1023\"\n\"Placebo\"\n64.0\n\"Male\"\n\n\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n71.0\n\"Male\"\n\n\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n74.0\n\"Male\"\n\n\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n77.0\n\"Female\"\n\n\n\n\n\n\nKey Polars operations for clinical reporting include:\n\n4.5.1 I/O\nPolars supports multiple data formats for input and output (see the I/O guide). For clinical development, we recommend the .parquet format because tools in Python, R, and Julia can read and write it without conversion. The example below loads subject-level ADSL data with Polars.\n\nimport polars as pl\nadsl = pl.read_parquet(\"data/adsl.parquet\")\nadsl = adsl.select(\"STUDYID\", \"USUBJID\", \"TRT01A\", \"AGE\", \"SEX\") # select columns\nadsl.head()\n\n\nshape: (5, 5)\n\n\n\nSTUDYID\nUSUBJID\nTRT01A\nAGE\nSEX\n\n\nstr\nstr\nstr\nf64\nstr\n\n\n\n\n\"CDISCPILOT01\"\n\"01-701-1015\"\n\"Placebo\"\n63.0\n\"Female\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1023\"\n\"Placebo\"\n64.0\n\"Male\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n71.0\n\"Male\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n74.0\n\"Male\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n77.0\n\"Female\"\n\n\n\n\n\n\n\n\n4.5.2 Filtering\nFiltering in Polars uses the .filter() method with column expressions. Below are examples applied to the ADSL data.\n\n# Filter female subjects\nadsl.filter(pl.col(\"SEX\") == \"Female\").head()\n\n\nshape: (5, 5)\n\n\n\nSTUDYID\nUSUBJID\nTRT01A\nAGE\nSEX\n\n\nstr\nstr\nstr\nf64\nstr\n\n\n\n\n\"CDISCPILOT01\"\n\"01-701-1015\"\n\"Placebo\"\n63.0\n\"Female\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n77.0\n\"Female\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1047\"\n\"Placebo\"\n85.0\n\"Female\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1111\"\n\"Xanomeline Low Dose\"\n81.0\n\"Female\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1133\"\n\"Xanomeline High Dose\"\n81.0\n\"Female\"\n\n\n\n\n\n\n\n# Filter subjects with Age &gt;= 65\nadsl.filter(pl.col(\"AGE\") &gt;= 65).head()\n\n\nshape: (5, 5)\n\n\n\nSTUDYID\nUSUBJID\nTRT01A\nAGE\nSEX\n\n\nstr\nstr\nstr\nf64\nstr\n\n\n\n\n\"CDISCPILOT01\"\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n71.0\n\"Male\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n74.0\n\"Male\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n77.0\n\"Female\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1047\"\n\"Placebo\"\n85.0\n\"Female\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1097\"\n\"Xanomeline Low Dose\"\n68.0\n\"Male\"\n\n\n\n\n\n\n\n\n4.5.3 Deriving\nDeriving new variables is common in clinical data analysis for creating age groups, BMI categories, or treatment flags. Polars uses .with_columns() to add new columns while keeping existing ones.\n\n# Create age groups\nadsl.with_columns([\n    pl.when(pl.col(\"AGE\") &lt; 65)\n      .then(pl.lit(\"&lt;65\"))\n      .otherwise(pl.lit(\"&gt;=65\"))\n      .alias(\"AGECAT\")\n]).head()\n\n\nshape: (5, 6)\n\n\n\nSTUDYID\nUSUBJID\nTRT01A\nAGE\nSEX\nAGECAT\n\n\nstr\nstr\nstr\nf64\nstr\nstr\n\n\n\n\n\"CDISCPILOT01\"\n\"01-701-1015\"\n\"Placebo\"\n63.0\n\"Female\"\n\"&lt;65\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1023\"\n\"Placebo\"\n64.0\n\"Male\"\n\"&lt;65\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n71.0\n\"Male\"\n\"&gt;=65\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n74.0\n\"Male\"\n\"&gt;=65\"\n\n\n\"CDISCPILOT01\"\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n77.0\n\"Female\"\n\"&gt;=65\"\n\n\n\n\n\n\n\n\n4.5.4 Grouping\nGrouping operations are fundamental for creating summary statistics in clinical reports. Polars uses group_by() followed by aggregation functions to compute counts, means, and other statistics by categorical variables like treatment groups.\nThe .count() method provides a quick way to get subject counts by group.\n\n# Count by treatment group\nadsl.group_by(\"TRT01A\").count().sort(\"TRT01A\")\n\n/tmp/ipykernel_6319/3512064118.py:2: DeprecationWarning: `GroupBy.count` was renamed; use `GroupBy.len` instead\n  adsl.group_by(\"TRT01A\").count().sort(\"TRT01A\")\n\n\n\nshape: (3, 2)\n\n\n\nTRT01A\ncount\n\n\nstr\nu32\n\n\n\n\n\"Placebo\"\n86\n\n\n\"Xanomeline High Dose\"\n84\n\n\n\"Xanomeline Low Dose\"\n84\n\n\n\n\n\n\nYou can also use .agg() with multiple aggregation functions:\n\n# Age statistics by treatment group\nadsl.group_by(\"TRT01A\").agg([\n    pl.col(\"AGE\").mean().round(1).alias(\"mean_age\"),\n    pl.col(\"AGE\").std().round(2).alias(\"sd_age\")\n]).sort(\"TRT01A\")\n\n\nshape: (3, 3)\n\n\n\nTRT01A\nmean_age\nsd_age\n\n\nstr\nf64\nf64\n\n\n\n\n\"Placebo\"\n75.2\n8.59\n\n\n\"Xanomeline High Dose\"\n74.4\n7.89\n\n\n\"Xanomeline Low Dose\"\n75.7\n8.29\n\n\n\n\n\n\n\n\n4.5.5 Joining\nJoining datasets is essential for combining subject-level data (ADSL) with event-level data (e.g. ADAE, ADLB). Polars supports various join types including inner, left, and full joins.\nHere is a toy example that splits ADSL and joins it back by USUBJID.\n\n# Create a simple demographics subset\ndemo = adsl.select(\"USUBJID\", \"AGE\", \"SEX\").head(3)\n\n# Create treatment info subset\ntrt = adsl.select(\"USUBJID\", \"TRT01A\").head(3)\n\n# Left join to combine datasets\ndemo.join(trt, on=\"USUBJID\", how=\"left\")\n\n\nshape: (3, 4)\n\n\n\nUSUBJID\nAGE\nSEX\nTRT01A\n\n\nstr\nf64\nstr\nstr\n\n\n\n\n\"01-701-1015\"\n63.0\n\"Female\"\n\"Placebo\"\n\n\n\"01-701-1023\"\n64.0\n\"Male\"\n\"Placebo\"\n\n\n\"01-701-1028\"\n71.0\n\"Male\"\n\"Xanomeline High Dose\"\n\n\n\n\n\n\n\n\n4.5.6 Pivoting\nPivoting transforms data from long to wide format, commonly needed for creating tables. Use .pivot() to reshape grouped data into columns.\n\n# Create summary by treatment and sex\n(\n    adsl\n        .group_by([\"TRT01A\", \"SEX\"])\n        .agg(pl.len().alias(\"n\"))\n        .pivot(\n            values=\"n\",\n            index=\"SEX\",\n            on=\"TRT01A\"\n        )\n)\n\n\nshape: (2, 4)\n\n\n\nSEX\nPlacebo\nXanomeline Low Dose\nXanomeline High Dose\n\n\nstr\nu32\nu32\nu32\n\n\n\n\n\"Male\"\n33\n34\n44\n\n\n\"Female\"\n53\n50\n40",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#rtflite",
    "href": "tlf-overview.html#rtflite",
    "title": "4  TLF overview",
    "section": "4.6 rtflite",
    "text": "4.6 rtflite\nrtflite is a Python package for creating production-ready tables and figures in RTF format. The package is designed to:\n\nProvide simple Python classes that map to table elements (title, headers, body, footnotes) for intuitive table construction.\nOffer a canonical Python API with a clear, composable interface.\nFocus exclusively on table formatting and layout, leaving data manipulation to dataframe libraries like polars or pandas.\nMinimize external dependencies for maximum portability and reliability.\n\nCreating an RTF table involves three steps:\n\nDesign the desired table layout and structure.\nConfigure the appropriate rtflite components.\nGenerate and save the RTF document.\n\nThis guide introduces rtflite’s core components and demonstrates how to turn dataframes into Tables, Listings, and Figures (TLFs) for clinical reporting.\n\n4.6.1 Data: adverse events\nTo explore the RTF generation capabilities in rtflite, we will use the dataset data/adae.parquet. This dataset contains adverse events (AE) information from a clinical trial.\nBelow is the meaning of relevant variables.\n\nUSUBJID: Unique Subject Identifier\nTRTA: Actual Treatment\nAEDECOD: Dictionary-Derived Term\n\n\nimport polars as pl\nimport rtflite as rtf\n\n\n# Load adverse events data\ndf = pl.read_parquet(\"data/adae.parquet\")\n\ndf.select([\"USUBJID\", \"TRTA\", \"AEDECOD\"])\n\n\nshape: (1_191, 3)\n\n\n\nUSUBJID\nTRTA\nAEDECOD\n\n\nstr\nstr\nstr\n\n\n\n\n\"01-701-1015\"\n\"Placebo\"\n\"APPLICATION SITE ERYTHEMA\"\n\n\n\"01-701-1015\"\n\"Placebo\"\n\"APPLICATION SITE PRURITUS\"\n\n\n\"01-701-1015\"\n\"Placebo\"\n\"DIARRHOEA\"\n\n\n\"01-701-1023\"\n\"Placebo\"\n\"ERYTHEMA\"\n\n\n\"01-701-1023\"\n\"Placebo\"\n\"ERYTHEMA\"\n\n\n…\n…\n…\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n\"APPLICATION SITE DERMATITIS\"\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n\"DECREASED APPETITE\"\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n\"NAUSEA\"\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n\"DECREASED APPETITE\"\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n\"NAUSEA\"\n\n\n\n\n\n\n\n\n4.6.2 Table-ready data\nIn this AE example, we provide the number of subjects with each type of AE by treatment group.\n\ntbl = (\n    df.group_by([\"TRTA\", \"AEDECOD\"])\n    .agg(pl.len().alias(\"n\"))\n    .sort(\"TRTA\")\n    .pivot(values=\"n\", index=\"AEDECOD\", on=\"TRTA\")\n    .fill_null(0)\n    .sort(\"AEDECOD\")  # Sort by adverse event name to match R output\n)\n\ntbl\n\n\nshape: (242, 4)\n\n\n\nAEDECOD\nPlacebo\nXanomeline High Dose\nXanomeline Low Dose\n\n\nstr\nu32\nu32\nu32\n\n\n\n\n\"ABDOMINAL DISCOMFORT\"\n0\n1\n0\n\n\n\"ABDOMINAL PAIN\"\n1\n2\n3\n\n\n\"ACROCHORDON EXCISION\"\n0\n1\n0\n\n\n\"ACTINIC KERATOSIS\"\n0\n1\n0\n\n\n\"AGITATION\"\n2\n1\n2\n\n\n…\n…\n…\n…\n\n\n\"WEIGHT DECREASED\"\n0\n2\n0\n\n\n\"WHITE BLOOD CELL COUNT INCREAS…\n0\n0\n2\n\n\n\"WOLFF-PARKINSON-WHITE SYNDROME\"\n0\n0\n2\n\n\n\"WOUND\"\n0\n0\n2\n\n\n\"WOUND HAEMORRHAGE\"\n0\n1\n0\n\n\n\n\n\n\n\n\n4.6.3 Table component classes\nrtflite provides dedicated classes for each table component. Commonly used classes include:\n\nRTFPage: RTF page information (orientation, margins, pagination).\nRTFPageHeader: Page headers with page numbering (compatible with r2rtf).\nRTFPageFooter: Page footers for attribution and notices.\nRTFTitle: RTF title information.\nRTFColumnHeader: RTF column header information.\nRTFBody: RTF table body information.\nRTFFootnote: RTF footnote information.\nRTFSource: RTF data source information.\n\nThese component classes work together to build complete RTF documents. A full list of all classes and their parameters can be found in the API reference.\n\n\n4.6.4 Simple example\nA minimal example below illustrates how to combine components to create an RTF table.\n\nRTFBody() defines table body layout.\nRTFDocument() transfers table layout information into RTF syntax.\nwrite_rtf() saves encoded RTF into a .rtf file.\n\n\n# Create simple RTF document\ndoc = rtf.RTFDocument(\n    df=tbl.head(6),\n    rtf_body=rtf.RTFBody(),  # Step 1: Add table attributes\n)\n\n# Step 2 & 3: Convert to RTF and write to file\ndoc.write_rtf(\"rtf/tlf_overview1.rtf\")\n\nrtf/tlf_overview1.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#column-width",
    "href": "tlf-overview.html#column-width",
    "title": "4  TLF overview",
    "section": "4.7 Column width",
    "text": "4.7 Column width\nIf we want to adjust the width of each column to provide more space to the first column, this can be achieved by updating col_rel_width in RTFBody.\nThe input of col_rel_width is a list with same length for number of columns. This argument defines the relative length of each column within a pre-defined total column width.\nIn this example, the defined relative width is 3:2:2:2. Only the ratio of col_rel_width is used. Therefore it is equivalent to use col_rel_width = [6,4,4,4] or col_rel_width = [1.5,1,1,1].\n\n# Create RTF document with custom column widths\ndoc = rtf.RTFDocument(\n    df=tbl.head(6),\n    rtf_body=rtf.RTFBody(\n        col_rel_width=[3, 2, 2, 2]  # Define relative width\n    ),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview2.rtf\")\n\nrtf/tlf_overview2.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#column-headers",
    "href": "tlf-overview.html#column-headers",
    "title": "4  TLF overview",
    "section": "4.8 Column headers",
    "text": "4.8 Column headers\nIn RTFColumnHeader, the text argument provides the column header content as a list of strings.\n\n# Create RTF document with column headers\ndoc = rtf.RTFDocument(\n    df=tbl.head(6),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Adverse Events\",\n            \"Placebo\",\n            \"Xanomeline High Dose\",\n            \"Xanomeline Low Dose\",\n        ],\n    ),\n    rtf_body=rtf.RTFBody(col_rel_width=[3, 2, 2, 2]),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview3.rtf\")\n\nrtf/tlf_overview3.rtf\n\n\n\nWe also allow column headers be displayed in multiple lines. If an empty column name is needed for a column, you can insert an empty string. For example, [\"name 1\", \"\", \"name 3\"].\nIn RTFColumnHeader, the col_rel_width can be used to align column header with different number of columns.\nBy using RTFColumnHeader with col_rel_width, one can customize complicated column headers. If there are multiple pages, column header will repeat at each page by default.\n\n# Create RTF document with multi-line column headers\ndoc = rtf.RTFDocument(\n    df=tbl.head(50),\n    rtf_page=rtf.RTFPage(nrow=15),\n    rtf_column_header=[\n        rtf.RTFColumnHeader(text=[\" \", \"Treatment\"], col_rel_width=[3, 3]),\n        rtf.RTFColumnHeader(\n            text=[\n                \"Adverse Events\",\n                \"Placebo\",\n                \"Xanomeline High Dose\",\n                \"Xanomeline Low Dose\",\n            ],\n            col_rel_width=[3, 1, 1, 1],\n        ),\n    ],\n    rtf_body=rtf.RTFBody(col_rel_width=[3, 1, 1, 1]),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview4.rtf\")\n\nrtf/tlf_overview4.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#titles-footnotes-and-data-source",
    "href": "tlf-overview.html#titles-footnotes-and-data-source",
    "title": "4  TLF overview",
    "section": "4.9 Titles, footnotes, and data source",
    "text": "4.9 Titles, footnotes, and data source\nRTF documents can include additional components to provide context and documentation:\n\nRTFTitle: Add document titles and subtitles\nRTFFootnote: Add explanatory footnotes\nRTFSource: Add data source attribution\n\n\n# Create RTF document with titles, footnotes, and source\ndoc = rtf.RTFDocument(\n    df=tbl.head(15),\n    rtf_title=rtf.RTFTitle(\n        text=[\"Summary of Adverse Events by Treatment Group\", \"Safety Analysis Set\"]\n    ),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Adverse Events\",\n            \"Placebo\\\\line (N=86)\",\n            \"Xanomeline High Dose\\\\line (N=84)\",\n            \"Xanomeline Low Dose\\\\line (N=84)\",\n        ],\n    ),\n    rtf_body=rtf.RTFBody(col_rel_width=[3, 2, 2, 2]),\n    rtf_footnote=rtf.RTFFootnote(\n        text=[\n            \"Adverse events are coded using MedDRA version 25.0.\",\n            \"Events are sorted alphabetically by preferred term.\",\n        ]\n    ),\n    rtf_source=rtf.RTFSource(text=\"Source: ADAE dataset, Data cutoff: 01JAN2023\"),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview5.rtf\")\n\nrtf/tlf_overview5.rtf\n\n\n\nNote the use of \\\\line in column headers to create line breaks within cells.",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#text-formatting-and-alignment",
    "href": "tlf-overview.html#text-formatting-and-alignment",
    "title": "4  TLF overview",
    "section": "4.10 Text formatting and alignment",
    "text": "4.10 Text formatting and alignment\nrtflite supports various text formatting options:\n\nText formatting: Bold (b), italic (i), underline (u), strikethrough (s)\nText alignment: Left (l), center (c), right (r), justify (j)\nFont properties: Font size, font family\n\n\n# Create RTF document with text formatting and alignment\ndoc = rtf.RTFDocument(\n    df=tbl.head(10),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Adverse Events\",\n            \"Placebo\",\n            \"Xanomeline High Dose\",\n            \"Xanomeline Low Dose\",\n        ],\n        text_format=\"b\",  # Bold headers\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n    ),\n    rtf_body=rtf.RTFBody(\n        col_rel_width=[3, 1, 1, 1],\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n    ),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview6.rtf\")\n\nrtf/tlf_overview6.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#border-customization",
    "href": "tlf-overview.html#border-customization",
    "title": "4  TLF overview",
    "section": "4.11 Border customization",
    "text": "4.11 Border customization\nTable borders can be customized extensively:\n\nBorder styles: single, double, thick, dotted, dashed\nBorder sides: border_top, border_bottom, border_left, border_right\nPage borders: border_first, border_last for first/last rows across pages\n\n\n# Create RTF document with custom borders\ndoc = rtf.RTFDocument(\n    df=tbl.head(8),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Adverse Events\",\n            \"Placebo\",\n            \"Xanomeline High Dose\",\n            \"Xanomeline Low Dose\",\n        ],\n        border_bottom=[\"single\", \"double\", \"single\", \"single\"],\n    ),\n    rtf_body=rtf.RTFBody(\n        col_rel_width=[3, 2, 2, 2],\n        border_left=[\"single\", \"\", \"\", \"\"],\n    ),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview7.rtf\")\n\nrtf/tlf_overview7.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#page-headers-and-footers",
    "href": "tlf-overview.html#page-headers-and-footers",
    "title": "4  TLF overview",
    "section": "4.12 Page headers and footers",
    "text": "4.12 Page headers and footers\nRTF documents can include page headers and footers that appear on every page, positioned outside the main content area (compatible with r2rtf):\n\nRTFPageHeader: Add headers with page numbering and custom text\nRTFPageFooter: Add footers with attribution or confidentiality notices\n\n\n# Create RTF document with page headers and footers\ndoc = rtf.RTFDocument(\n    df=tbl.head(15),\n    rtf_page_header=rtf.RTFPageHeader(\n        # Default: \"Page \\chpgn of {\\field{\\*\\fldinst NUMPAGES }}\"\n        # Uses r2rtf-compatible RTF field codes\n    ),\n    rtf_page_footer=rtf.RTFPageFooter(text=\"Confidential - Clinical Study Report\"),\n    rtf_title=rtf.RTFTitle(\n        text=[\n            \"Summary of Adverse Events by Treatment Group\",\n            \"With Page Headers and Footers\",\n        ]\n    ),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Adverse Events\",\n            \"Placebo (N=86)\",\n            \"Xanomeline High Dose (N=84)\",\n            \"Xanomeline Low Dose (N=84)\",\n        ],\n    ),\n    rtf_body=rtf.RTFBody(col_rel_width=[3, 2, 2, 2]),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview8.rtf\")\n\nrtf/tlf_overview8.rtf\n\n\n\n\n4.12.1 Custom header and footer formatting\nHeaders and footers support full text formatting including custom alignment, font sizes, and styling:\n\n# Create RTF document with custom formatted headers and footers\ndoc = rtf.RTFDocument(\n    df=tbl.head(10),\n    rtf_page_header=rtf.RTFPageHeader(\n        text=\"Study XYZ-123 | Page \\\\chpgn\",\n        text_font_size=10,\n        text_justification=\"c\",  # Center aligned\n        text_format=\"b\",  # Bold\n    ),\n    rtf_page_footer=rtf.RTFPageFooter(\n        text=[\"Company Confidential\"],\n        text_font_size=8,\n        text_justification=\"l\",  # Left aligned\n    ),\n    rtf_title=rtf.RTFTitle(text=\"Adverse Events with Custom Headers/Footers\"),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Adverse Events\",\n            \"Placebo\",\n            \"Xanomeline High Dose\",\n            \"Xanomeline Low Dose\",\n        ],\n    ),\n    rtf_body=rtf.RTFBody(col_rel_width=[3, 2, 2, 2]),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview8b.rtf\")\n\nrtf/tlf_overview8b.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-overview.html#page-layout-and-orientation",
    "href": "tlf-overview.html#page-layout-and-orientation",
    "title": "4  TLF overview",
    "section": "4.13 Page layout and orientation",
    "text": "4.13 Page layout and orientation\nRTFPage provides control over page layout:\n\nOrientation: portrait or landscape\nPage size: Custom width and height\nMargins: Left, right, top, bottom, header, footer margins\nRows per page: Control pagination with nrow\n\n\n# Create RTF document with landscape layout\ndoc = rtf.RTFDocument(\n    df=tbl.head(20),\n    rtf_page=rtf.RTFPage(\n        orientation=\"landscape\",  # Landscape for wider tables\n        nrow=10,\n        border_first=\"dashed\",  # Dash border for first/last pages\n        border_last=\"dashed\",\n    ),\n    rtf_title=rtf.RTFTitle(text=\"Adverse Events Summary - Landscape Layout\"),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Adverse Events\",\n            \"Placebo (N=86)\",\n            \"Xanomeline High Dose (N=84)\",\n            \"Xanomeline Low Dose (N=84)\",\n        ],\n    ),\n    rtf_body=rtf.RTFBody(col_rel_width=[4, 2, 2, 2]),\n)\n\ndoc.write_rtf(\"rtf/tlf_overview10.rtf\")\n\nrtf/tlf_overview10.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TLF overview</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html",
    "href": "tlf-disposition.html",
    "title": "5  Disposition of participants",
    "section": "",
    "text": "5.1 Overview\nClinical trials needs to track how participants flow through a study from enrollment to completion. Following ICH E3 guidance, regulatory submissions require a disposition table in Section 10.1 that summarizes:\nThis tutorial shows you how to create a regulatory-compliant disposition table using Python’s rtflite package.\nimport polars as pl # Manipulate data\nimport rtflite as rtf # Reporting in RTF format",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#overview",
    "href": "tlf-disposition.html#overview",
    "title": "5  Disposition of participants",
    "section": "",
    "text": "Enrolled: Total participants who entered the study\nCompleted: Participants who finished the study protocol\nDiscontinued: Participants who left early and their reasons",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#step-1-load-data",
    "href": "tlf-disposition.html#step-1-load-data",
    "title": "5  Disposition of participants",
    "section": "5.2 Step 1: Load Data",
    "text": "5.2 Step 1: Load Data\nWe start by loading the Subject-level Analysis Dataset (ADSL), which contains all participant information needed for our disposition table.\nThe ADSL dataset stores participant-level information including treatment assignments and study completion status. We’re using the parquet format for data storage.\n\nadsl = pl.read_parquet(\"data/adsl.parquet\")\n\nLet’s examine the key variables we’ll use to build our disposition table:\n\nUSUBJID: Unique identifier for each participant\nTRT01P: Treatment name (text)\nTRT01PN: Treatment group (numeric code)\nDISCONFL: Flag indicating if participant discontinued (Y/N)\nDCREASCD: Specific reason for discontinuation\n\n\nadsl.select([\"USUBJID\", \"TRT01P\", \"TRT01PN\", \"DISCONFL\", \"DCREASCD\"])\n\n\nshape: (254, 5)\n\n\n\nUSUBJID\nTRT01P\nTRT01PN\nDISCONFL\nDCREASCD\n\n\nstr\nstr\ni64\nstr\nstr\n\n\n\n\n\"01-701-1015\"\n\"Placebo\"\n0\n\"\"\n\"Completed\"\n\n\n\"01-701-1023\"\n\"Placebo\"\n0\n\"Y\"\n\"Adverse Event\"\n\n\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n81\n\"\"\n\"Completed\"\n\n\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n54\n\"Y\"\n\"Sponsor Decision\"\n\n\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n81\n\"\"\n\"Completed\"\n\n\n…\n…\n…\n…\n…\n\n\n\"01-718-1254\"\n\"Xanomeline Low Dose\"\n54\n\"\"\n\"Completed\"\n\n\n\"01-718-1328\"\n\"Xanomeline High Dose\"\n81\n\"Y\"\n\"Withdrew Consent\"\n\n\n\"01-718-1355\"\n\"Placebo\"\n0\n\"\"\n\"Completed\"\n\n\n\"01-718-1371\"\n\"Xanomeline High Dose\"\n81\n\"Y\"\n\"Adverse Event\"\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n81\n\"Y\"\n\"Lack of Efficacy\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#step-2-count-total-participants",
    "href": "tlf-disposition.html#step-2-count-total-participants",
    "title": "5  Disposition of participants",
    "section": "5.3 Step 2: Count Total Participants",
    "text": "5.3 Step 2: Count Total Participants\nFirst, we count how many participants were enrolled in each treatment group.\nWe group participants by treatment arm and count them using .group_by() and .agg(). The .pivot() operation reshapes our data from long format (rows for each treatment) to wide format (columns for each treatment), which matches the standard disposition table layout.\n\nn_rand = (\n    adsl\n    .group_by(\"TRT01PN\")\n    .agg(n = pl.len())\n    .with_columns([\n        pl.lit(\"Participants in population\").alias(\"row\"),\n        pl.lit(None, dtype=pl.Float64).alias(\"pct\") # Placeholder for percentage (not applicable for totals)\n    ])\n    .pivot(\n        index=\"row\",\n        on=\"TRT01PN\",\n        values=[\"n\", \"pct\"],\n        sort_columns=True\n    )\n)\n\nn_rand\n\n\nshape: (1, 7)\n\n\n\nrow\nn_0\nn_54\nn_81\npct_0\npct_54\npct_81\n\n\nstr\nu32\nu32\nu32\nf64\nf64\nf64\n\n\n\n\n\"Participants in population\"\n86\n84\n84\nnull\nnull\nnull",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#step-3-count-completed-participants",
    "href": "tlf-disposition.html#step-3-count-completed-participants",
    "title": "5  Disposition of participants",
    "section": "5.4 Step 3: Count Completed Participants",
    "text": "5.4 Step 3: Count Completed Participants\nNext, we identify participants who successfully completed the study and calculate what percentage they represent of each treatment group.\nWe filter for participants where DCREASCD == \"Completed\", then calculate both counts and percentages. The .join() operation brings in the total count for each treatment group so we can compute percentages.\n\nn_complete = (\n    adsl\n    .filter(pl.col(\"DCREASCD\") == \"Completed\")\n    .group_by(\"TRT01PN\")\n    .agg(n = pl.len())\n    .join(\n        adsl.group_by(\"TRT01PN\").agg(total = pl.len()),\n        on=\"TRT01PN\"\n    )\n    .with_columns([\n        pl.lit(\"Completed\").alias(\"row\"),\n        (100.0 * pl.col(\"n\") / pl.col(\"total\")).round(1).alias(\"pct\")\n    ])\n    .pivot(\n        index=\"row\",\n        on=\"TRT01PN\",\n        values=[\"n\", \"pct\"],\n        sort_columns=True\n    )\n)\n\nn_complete\n\n\nshape: (1, 7)\n\n\n\nrow\nn_0\nn_54\nn_81\npct_0\npct_54\npct_81\n\n\nstr\nu32\nu32\nu32\nf64\nf64\nf64\n\n\n\n\n\"Completed\"\n58\n25\n27\n67.4\n29.8\n32.1",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#step-4-count-discontinued-participants",
    "href": "tlf-disposition.html#step-4-count-discontinued-participants",
    "title": "5  Disposition of participants",
    "section": "5.5 Step 4: Count Discontinued Participants",
    "text": "5.5 Step 4: Count Discontinued Participants\nNow we count participants who left the study early, regardless of their specific reason.\nWe filter for participants where the discontinuation flag DISCONFL == \"Y\", then follow the same pattern of counting and calculating percentages within each treatment group.\n\nn_disc = (\n    adsl\n    .filter(pl.col(\"DISCONFL\") == \"Y\")\n    .group_by(\"TRT01PN\")\n    .agg(n = pl.len())\n    .join(\n        adsl.group_by(\"TRT01PN\").agg(total = pl.len()),\n        on=\"TRT01PN\"\n    )\n    .with_columns([\n        pl.lit(\"Discontinued\").alias(\"row\"),\n        (100.0 * pl.col(\"n\") / pl.col(\"total\")).round(1).alias(\"pct\")\n    ])\n    .pivot(\n        index=\"row\",\n        on=\"TRT01PN\",\n        values=[\"n\", \"pct\"],\n        sort_columns=True\n    )\n)\n\nn_disc\n\n\nshape: (1, 7)\n\n\n\nrow\nn_0\nn_54\nn_81\npct_0\npct_54\npct_81\n\n\nstr\nu32\nu32\nu32\nf64\nf64\nf64\n\n\n\n\n\"Discontinued\"\n28\n59\n57\n32.6\n70.2\n67.9",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#step-5-break-down-discontinuation-reasons",
    "href": "tlf-disposition.html#step-5-break-down-discontinuation-reasons",
    "title": "5  Disposition of participants",
    "section": "5.6 Step 5: Break Down Discontinuation Reasons",
    "text": "5.6 Step 5: Break Down Discontinuation Reasons\nFor regulatory reporting, we need to show the specific reasons why participants discontinued.\nWe filter out completed participants, then group by both treatment and discontinuation reason. The indentation (four spaces) in the row labels helps show these are subcategories under “Discontinued”. We also use .fill_null(0) to handle cases where certain discontinuation reasons don’t occur in all treatment groups.\n\nn_reason = (\n    adsl\n    .filter(pl.col(\"DCREASCD\") != \"Completed\")\n    .group_by([\"TRT01PN\", \"DCREASCD\"])\n    .agg(n = pl.len())\n    .join(\n        adsl.group_by(\"TRT01PN\").agg(total = pl.len()),\n        on=\"TRT01PN\"\n    )\n    .with_columns([\n        pl.concat_str([pl.lit(\"    \"), pl.col(\"DCREASCD\")]).alias(\"row\"),\n        (100.0 * pl.col(\"n\") / pl.col(\"total\")).round(1).alias(\"pct\")\n    ])\n    .pivot(\n        index=\"row\",\n        on=\"TRT01PN\",\n        values=[\"n\", \"pct\"],\n        sort_columns=True\n    )\n    .with_columns([\n        pl.col([\"n_0\", \"n_54\", \"n_81\"]).fill_null(0),\n        pl.col([\"pct_0\", \"pct_54\", \"pct_81\"]).fill_null(0.0)\n    ])\n    .sort(\"row\")\n)\n\nn_reason\n\n\nshape: (9, 7)\n\n\n\nrow\nn_0\nn_54\nn_81\npct_0\npct_54\npct_81\n\n\nstr\nu32\nu32\nu32\nf64\nf64\nf64\n\n\n\n\n\"    Adverse Event\"\n8\n44\n40\n9.3\n52.4\n47.6\n\n\n\"    Death\"\n2\n1\n0\n2.3\n1.2\n0.0\n\n\n\"    I/E Not Met\"\n1\n0\n2\n1.2\n0.0\n2.4\n\n\n\"    Lack of Efficacy\"\n3\n0\n1\n3.5\n0.0\n1.2\n\n\n\"    Lost to Follow-up\"\n1\n1\n0\n1.2\n1.2\n0.0\n\n\n\"    Physician Decision\"\n1\n0\n2\n1.2\n0.0\n2.4\n\n\n\"    Protocol Violation\"\n1\n1\n1\n1.2\n1.2\n1.2\n\n\n\"    Sponsor Decision\"\n2\n2\n3\n2.3\n2.4\n3.6\n\n\n\"    Withdrew Consent\"\n9\n10\n8\n10.5\n11.9\n9.5",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#step-6-combine-all-results",
    "href": "tlf-disposition.html#step-6-combine-all-results",
    "title": "5  Disposition of participants",
    "section": "5.7 Step 6: Combine All Results",
    "text": "5.7 Step 6: Combine All Results\nNow we stack all our individual summaries together to create the complete disposition table.\nUsing pl.concat(), we combine the enrollment counts, completion counts, discontinuation counts, and detailed discontinuation reasons into a single table that flows logically from top to bottom.\n\ntbl_disp = pl.concat([\n    n_rand,\n    n_complete,\n    n_disc,\n    n_reason\n])\n\ntbl_disp\n\n\nshape: (12, 7)\n\n\n\nrow\nn_0\nn_54\nn_81\npct_0\npct_54\npct_81\n\n\nstr\nu32\nu32\nu32\nf64\nf64\nf64\n\n\n\n\n\"Participants in population\"\n86\n84\n84\nnull\nnull\nnull\n\n\n\"Completed\"\n58\n25\n27\n67.4\n29.8\n32.1\n\n\n\"Discontinued\"\n28\n59\n57\n32.6\n70.2\n67.9\n\n\n\"    Adverse Event\"\n8\n44\n40\n9.3\n52.4\n47.6\n\n\n\"    Death\"\n2\n1\n0\n2.3\n1.2\n0.0\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n\"    Lost to Follow-up\"\n1\n1\n0\n1.2\n1.2\n0.0\n\n\n\"    Physician Decision\"\n1\n0\n2\n1.2\n0.0\n2.4\n\n\n\"    Protocol Violation\"\n1\n1\n1\n1.2\n1.2\n1.2\n\n\n\"    Sponsor Decision\"\n2\n2\n3\n2.3\n2.4\n3.6\n\n\n\"    Withdrew Consent\"\n9\n10\n8\n10.5\n11.9\n9.5",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-disposition.html#step-7-generate-publication-ready-output",
    "href": "tlf-disposition.html#step-7-generate-publication-ready-output",
    "title": "5  Disposition of participants",
    "section": "5.8 Step 7: Generate Publication-Ready Output",
    "text": "5.8 Step 7: Generate Publication-Ready Output\nFinally, we format our table in RTF format using the rtflite package.\nThe RTFDocument class handles the complex formatting required for clinical reports, including proper column headers, borders, and spacing. The resulting RTF file can be directly included in regulatory submissions or converted to PDF for review.\n\ndoc_disp = rtf.RTFDocument(\n    df=tbl_disp.select(\"row\", \"n_0\", \"pct_0\", \"n_54\", \"pct_54\", \"n_81\", \"pct_81\"),\n    rtf_title=rtf.RTFTitle(text=[\"Disposition of Participants\"]),\n    rtf_column_header=[\n        rtf.RTFColumnHeader(\n            text=[\"\", \"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"],\n            col_rel_width=[3] + [2] * 3,\n            text_justification=[\"l\"] + [\"c\"] * 3,\n        ),\n        rtf.RTFColumnHeader(\n            text=[\"\", \"n\", \"(%)\", \"n\", \"(%)\", \"n\", \"(%)\"],\n            col_rel_width=[3] + [1] * 6,\n            text_justification=[\"l\"] + [\"c\"] * 6,\n            border_top=[\"\"] + [\"single\"] * 6,\n            border_left=[\"single\"] + [\"single\", \"\"] * 3\n        )\n    ],\n    rtf_body=rtf.RTFBody(\n        col_rel_width=[3] + [1] * 6,\n        text_justification=[\"l\"] + [\"c\"] * 6,\n        border_left=[\"single\"] + [\"single\", \"\"] * 3\n    ),\n    rtf_source=rtf.RTFSource(text=[\"Source: ADSL dataset\"]) # Required source attribution\n)\n\ndoc_disp.write_rtf(\"rtf/tlf_disposition.rtf\")  # Save as RTF for submission\n\nrtf/tlf_disposition.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Disposition of participants</span>"
    ]
  },
  {
    "objectID": "tlf-population.html",
    "href": "tlf-population.html",
    "title": "6  Study population",
    "section": "",
    "text": "6.1 Overview\nClinical trials define multiple analysis populations based on different inclusion criteria. Following ICH E3 guidance, regulatory submissions must clearly document the number of participants in each analysis population to support the validity of statistical analyses.\nThe key analysis populations typically include:\nThis tutorial shows you how to create a population summary table using Python’s rtflite package.\nimport polars as pl # Data manipulation\nimport rtflite as rtf # RTF reporting",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#overview",
    "href": "tlf-population.html#overview",
    "title": "6  Study population",
    "section": "",
    "text": "All Randomized: Total participants who entered the study\nIntent-to-Treat (ITT): Participants included in the primary efficacy analysis\nEfficacy Population: Participants who meet specific criteria for efficacy evaluation\nSafety Population: Participants who received at least one dose of study treatment",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-1-load-data",
    "href": "tlf-population.html#step-1-load-data",
    "title": "6  Study population",
    "section": "6.2 Step 1: Load Data",
    "text": "6.2 Step 1: Load Data\nWe start by loading the Subject-level Analysis Dataset (ADSL), which contains population flags for each participant.\n\nadsl = pl.read_parquet(\"data/adsl.parquet\")\n\nLet’s examine the key population flag variables we’ll use:\n\nUSUBJID: Unique participant identifier\nTRT01P: Planned treatment group\nITTFL: Intent-to-treat population flag (Y/N)\nEFFFL: Efficacy population flag (Y/N)\nSAFFL: Safety population flag (Y/N)\n\n\nadsl.select([\"USUBJID\", \"TRT01P\", \"ITTFL\", \"EFFFL\", \"SAFFL\"])\n\n\nshape: (254, 5)\n\n\n\nUSUBJID\nTRT01P\nITTFL\nEFFFL\nSAFFL\n\n\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"01-701-1015\"\n\"Placebo\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-701-1023\"\n\"Placebo\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n…\n…\n…\n…\n…\n\n\n\"01-718-1254\"\n\"Xanomeline Low Dose\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-718-1328\"\n\"Xanomeline High Dose\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-718-1355\"\n\"Placebo\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-718-1371\"\n\"Xanomeline High Dose\"\n\"Y\"\n\"Y\"\n\"Y\"\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n\"Y\"\n\"Y\"\n\"Y\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-2-calculate-treatment-group-totals",
    "href": "tlf-population.html#step-2-calculate-treatment-group-totals",
    "title": "6  Study population",
    "section": "6.3 Step 2: Calculate Treatment Group Totals",
    "text": "6.3 Step 2: Calculate Treatment Group Totals\nFirst, we calculate the total number of randomized participants in each treatment group, which will serve as the denominator for percentage calculations.\n\ntotals = adsl.group_by(\"TRT01P\").agg(\n    total = pl.len()\n)\n\ntotals\n\n\nshape: (3, 2)\n\n\n\nTRT01P\ntotal\n\n\nstr\nu32\n\n\n\n\n\"Xanomeline Low Dose\"\n84\n\n\n\"Xanomeline High Dose\"\n84\n\n\n\"Placebo\"\n86",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-3-define-helper-function",
    "href": "tlf-population.html#step-3-define-helper-function",
    "title": "6  Study population",
    "section": "6.4 Step 3: Define Helper Function",
    "text": "6.4 Step 3: Define Helper Function\nWe create a reusable function to count participants by treatment group for any population subset.\n\ndef count_by_treatment(data, population_name):\n    \"\"\"Count participants by treatment group and add population label\"\"\"\n    return data.group_by(\"TRT01P\").agg(\n        n = pl.len()\n    ).with_columns(\n        population = pl.lit(population_name)\n    )",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-4-count-each-population",
    "href": "tlf-population.html#step-4-count-each-population",
    "title": "6  Study population",
    "section": "6.5 Step 4: Count Each Population",
    "text": "6.5 Step 4: Count Each Population\nNow we calculate participant counts for each analysis population.\n\n6.5.1 All Randomized Participants\n\npop_all = count_by_treatment(\n    data=adsl,\n    population_name=\"Participants in population\"\n)\n\npop_all\n\n\nshape: (3, 3)\n\n\n\nTRT01P\nn\npopulation\n\n\nstr\nu32\nstr\n\n\n\n\n\"Placebo\"\n86\n\"Participants in population\"\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants in population\"\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants in population\"\n\n\n\n\n\n\n\n\n6.5.2 Intent-to-Treat Population\n\nadsl_itt = adsl.filter(pl.col(\"ITTFL\") == \"Y\")\npop_itt = count_by_treatment(\n    data=adsl_itt,\n    population_name=\"Participants included in ITT population\"\n)\n\npop_itt\n\n\nshape: (3, 3)\n\n\n\nTRT01P\nn\npopulation\n\n\nstr\nu32\nstr\n\n\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in ITT p…\n\n\n\"Placebo\"\n86\n\"Participants included in ITT p…\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants included in ITT p…\n\n\n\n\n\n\n\n\n6.5.3 Efficacy Population\n\nadsl_eff = adsl.filter(pl.col(\"EFFFL\") == \"Y\")\npop_eff = count_by_treatment(\n    data=adsl_eff,\n    population_name=\"Participants included in efficacy population\"\n)\n\npop_eff\n\n\nshape: (3, 3)\n\n\n\nTRT01P\nn\npopulation\n\n\nstr\nu32\nstr\n\n\n\n\n\"Xanomeline Low Dose\"\n81\n\"Participants included in effic…\n\n\n\"Xanomeline High Dose\"\n74\n\"Participants included in effic…\n\n\n\"Placebo\"\n79\n\"Participants included in effic…\n\n\n\n\n\n\n\n\n6.5.4 Safety Population\n\nadsl_saf = adsl.filter(pl.col(\"SAFFL\") == \"Y\")\npop_saf = count_by_treatment(\n    data=adsl_saf,\n    population_name=\"Participants included in safety population\"\n)\n\npop_saf\n\n\nshape: (3, 3)\n\n\n\nTRT01P\nn\npopulation\n\n\nstr\nu32\nstr\n\n\n\n\n\"Placebo\"\n86\n\"Participants included in safet…\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants included in safet…\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in safet…",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-5-combine-all-populations",
    "href": "tlf-population.html#step-5-combine-all-populations",
    "title": "6  Study population",
    "section": "6.6 Step 5: Combine All Populations",
    "text": "6.6 Step 5: Combine All Populations\nWe stack all population counts together into a single dataset.\n\nall_populations = pl.concat([\n    pop_all,\n    pop_itt,\n    pop_eff,\n    pop_saf\n])\n\nall_populations\n\n\nshape: (12, 3)\n\n\n\nTRT01P\nn\npopulation\n\n\nstr\nu32\nstr\n\n\n\n\n\"Placebo\"\n86\n\"Participants in population\"\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants in population\"\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants in population\"\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in ITT p…\n\n\n\"Placebo\"\n86\n\"Participants included in ITT p…\n\n\n…\n…\n…\n\n\n\"Xanomeline High Dose\"\n74\n\"Participants included in effic…\n\n\n\"Placebo\"\n79\n\"Participants included in effic…\n\n\n\"Placebo\"\n86\n\"Participants included in safet…\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants included in safet…\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in safet…",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-6-calculate-percentages",
    "href": "tlf-population.html#step-6-calculate-percentages",
    "title": "6  Study population",
    "section": "6.7 Step 6: Calculate Percentages",
    "text": "6.7 Step 6: Calculate Percentages\nWe join with the total counts and calculate what percentage each population represents of the total randomized participants.\n\nstats_with_pct = all_populations.join(\n    totals,\n    on=\"TRT01P\"\n).with_columns(\n    pct = (100.0 * pl.col(\"n\") / pl.col(\"total\")).round(1)\n)\n\nstats_with_pct\n\n\nshape: (12, 5)\n\n\n\nTRT01P\nn\npopulation\ntotal\npct\n\n\nstr\nu32\nstr\nu32\nf64\n\n\n\n\n\"Placebo\"\n86\n\"Participants in population\"\n86\n100.0\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants in population\"\n84\n100.0\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants in population\"\n84\n100.0\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in ITT p…\n84\n100.0\n\n\n\"Placebo\"\n86\n\"Participants included in ITT p…\n86\n100.0\n\n\n…\n…\n…\n…\n…\n\n\n\"Xanomeline High Dose\"\n74\n\"Participants included in effic…\n84\n88.1\n\n\n\"Placebo\"\n79\n\"Participants included in effic…\n86\n91.9\n\n\n\"Placebo\"\n86\n\"Participants included in safet…\n86\n100.0\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants included in safet…\n84\n100.0\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in safet…\n84\n100.0",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-7-format-display-values",
    "href": "tlf-population.html#step-7-format-display-values",
    "title": "6  Study population",
    "section": "6.8 Step 7: Format Display Values",
    "text": "6.8 Step 7: Format Display Values\nFor the final table, we format the display text. The total randomized count shows just “N”, while subset populations show “N (%)”.\n\nformatted_stats = stats_with_pct.with_columns(\n    display = pl.when(pl.col(\"population\") == \"Participants in population\")\n        .then(pl.col(\"n\").cast(str)) \n        .otherwise(\n            pl.concat_str([ \n                pl.col(\"n\").cast(str),\n                pl.lit(\" (\"),\n                pl.col(\"pct\").round(1).cast(str),\n                pl.lit(\")\")\n            ])\n        )\n)\n\nformatted_stats\n\n\nshape: (12, 6)\n\n\n\nTRT01P\nn\npopulation\ntotal\npct\ndisplay\n\n\nstr\nu32\nstr\nu32\nf64\nstr\n\n\n\n\n\"Placebo\"\n86\n\"Participants in population\"\n86\n100.0\n\"86\"\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants in population\"\n84\n100.0\n\"84\"\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants in population\"\n84\n100.0\n\"84\"\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in ITT p…\n84\n100.0\n\"84 (100.0)\"\n\n\n\"Placebo\"\n86\n\"Participants included in ITT p…\n86\n100.0\n\"86 (100.0)\"\n\n\n…\n…\n…\n…\n…\n…\n\n\n\"Xanomeline High Dose\"\n74\n\"Participants included in effic…\n84\n88.1\n\"74 (88.1)\"\n\n\n\"Placebo\"\n79\n\"Participants included in effic…\n86\n91.9\n\"79 (91.9)\"\n\n\n\"Placebo\"\n86\n\"Participants included in safet…\n86\n100.0\n\"86 (100.0)\"\n\n\n\"Xanomeline Low Dose\"\n84\n\"Participants included in safet…\n84\n100.0\n\"84 (100.0)\"\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants included in safet…\n84\n100.0\n\"84 (100.0)\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-8-create-final-table",
    "href": "tlf-population.html#step-8-create-final-table",
    "title": "6  Study population",
    "section": "6.9 Step 8: Create Final Table",
    "text": "6.9 Step 8: Create Final Table\nWe reshape the data from long format (rows for each treatment-population combination) to wide format (columns for each treatment group).\n\ndf_overview = formatted_stats.pivot(\n    values=\"display\",\n    index=\"population\",\n    on=\"TRT01P\",\n    maintain_order=True\n).select(\n    [\"population\", \"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]\n)\n\ndf_overview\n\n\nshape: (4, 4)\n\n\n\npopulation\nPlacebo\nXanomeline Low Dose\nXanomeline High Dose\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"Participants in population\"\n\"86\"\n\"84\"\n\"84\"\n\n\n\"Participants included in ITT p…\n\"86 (100.0)\"\n\"84 (100.0)\"\n\"84 (100.0)\"\n\n\n\"Participants included in effic…\n\"79 (91.9)\"\n\"81 (96.4)\"\n\"74 (88.1)\"\n\n\n\"Participants included in safet…\n\"86 (100.0)\"\n\"84 (100.0)\"\n\"84 (100.0)\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-population.html#step-9-generate-publication-ready-output",
    "href": "tlf-population.html#step-9-generate-publication-ready-output",
    "title": "6  Study population",
    "section": "6.10 Step 9: Generate Publication-Ready Output",
    "text": "6.10 Step 9: Generate Publication-Ready Output\nFinally, we format the population table for regulatory submission using the rtflite package.\n\ndoc_overview = rtf.RTFDocument(\n    df=df_overview,\n    rtf_title=rtf.RTFTitle(\n        text=[\"Analysis Population\", \"All Participants Randomized\"]\n    ),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\"\", \"Placebo\\nn (%)\", \"Xanomeline Low Dose\\nn (%)\", \"Xanomeline High Dose\\nn (%)\"],\n        col_rel_width=[4, 2, 2, 2],\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n    ),\n    rtf_body=rtf.RTFBody(\n        col_rel_width=[4, 2, 2, 2],\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n    ),\n    rtf_source=rtf.RTFSource(text=[\"Source: ADSL dataset\"])\n)\n\ndoc_overview.write_rtf(\"rtf/tlf_population.rtf\")\n\nrtf/tlf_population.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Study population</span>"
    ]
  },
  {
    "objectID": "tlf-baseline.html",
    "href": "tlf-baseline.html",
    "title": "7  Baseline characteristics",
    "section": "",
    "text": "7.1 Overview\nBaseline characteristics tables summarize the demographic and clinical characteristics of study participants at enrollment. Following ICH E3 guidance, these tables are essential for understanding the study population and assessing comparability between treatment groups.\nThis tutorial shows you how to create a baseline characteristics table using Python’s rtflite package.\nimport polars as pl # Data manipulation\nimport rtflite as rtf # RTF reporting",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Baseline characteristics</span>"
    ]
  },
  {
    "objectID": "tlf-baseline.html#step-1-load-data",
    "href": "tlf-baseline.html#step-1-load-data",
    "title": "7  Baseline characteristics",
    "section": "7.2 Step 1: Load Data",
    "text": "7.2 Step 1: Load Data\nWe start by loading the Subject-level Analysis Dataset (ADSL) and filtering to the safety population.\n\nadsl = (\n    pl.read_parquet(\"data/adsl.parquet\")\n    .select([\"USUBJID\", \"TRT01P\", \"AGE\", \"SEX\", \"RACE\"])\n)\n\nadsl\n\n\nshape: (254, 5)\n\n\n\nUSUBJID\nTRT01P\nAGE\nSEX\nRACE\n\n\nstr\nstr\nf64\nstr\nstr\n\n\n\n\n\"01-701-1015\"\n\"Placebo\"\n63.0\n\"Female\"\n\"White\"\n\n\n\"01-701-1023\"\n\"Placebo\"\n64.0\n\"Male\"\n\"White\"\n\n\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n71.0\n\"Male\"\n\"White\"\n\n\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n74.0\n\"Male\"\n\"White\"\n\n\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n77.0\n\"Female\"\n\"White\"\n\n\n…\n…\n…\n…\n…\n\n\n\"01-718-1254\"\n\"Xanomeline Low Dose\"\n78.0\n\"Male\"\n\"White\"\n\n\n\"01-718-1328\"\n\"Xanomeline High Dose\"\n86.0\n\"Male\"\n\"White\"\n\n\n\"01-718-1355\"\n\"Placebo\"\n79.0\n\"Male\"\n\"White\"\n\n\n\"01-718-1371\"\n\"Xanomeline High Dose\"\n69.0\n\"Female\"\n\"White\"\n\n\n\"01-718-1427\"\n\"Xanomeline High Dose\"\n74.0\n\"Female\"\n\"Black Or African American\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Baseline characteristics</span>"
    ]
  },
  {
    "objectID": "tlf-baseline.html#step-2-calculate-summary-statistics",
    "href": "tlf-baseline.html#step-2-calculate-summary-statistics",
    "title": "7  Baseline characteristics",
    "section": "7.3 Step 2: Calculate Summary Statistics",
    "text": "7.3 Step 2: Calculate Summary Statistics\nWe’ll create separate functions to handle continuous and categorical variables.\n\n7.3.1 Continuous Variables (Age)\nFor continuous variables, we calculate mean (SD) and median [min, max].\n\ndef summarize_continuous(df, var):\n    \"\"\"Calculate summary statistics for continuous variables\"\"\"\n    return df.group_by(\"TRT01P\").agg([\n        pl.col(var).mean().round(1).alias(\"mean\"),\n        pl.col(var).std().round(2).alias(\"sd\"),\n        pl.col(var).median().alias(\"median\"),\n        pl.col(var).min().alias(\"min\"),\n        pl.col(var).max().alias(\"max\"),\n        pl.len().alias(\"n\")\n    ])\n\nage_stats = summarize_continuous(adsl, \"AGE\")\nage_stats\n\n\nshape: (3, 7)\n\n\n\nTRT01P\nmean\nsd\nmedian\nmin\nmax\nn\n\n\nstr\nf64\nf64\nf64\nf64\nf64\nu32\n\n\n\n\n\"Placebo\"\n75.2\n8.59\n76.0\n52.0\n89.0\n86\n\n\n\"Xanomeline Low Dose\"\n75.7\n8.29\n77.5\n51.0\n88.0\n84\n\n\n\"Xanomeline High Dose\"\n74.4\n7.89\n76.0\n56.0\n88.0\n84\n\n\n\n\n\n\n\n\n7.3.2 Categorical Variables (Sex, Race)\nFor categorical variables, we calculate counts and percentages.\n\ndef summarize_categorical(df, var):\n    \"\"\"Calculate counts and percentages for categorical variables\"\"\"\n    # Get counts by treatment and category\n    counts = df.group_by([\"TRT01P\", var]).len()\n\n    # Get treatment totals for percentage calculations\n    totals = df.group_by(\"TRT01P\").len().rename({\"len\": \"total\"})\n\n    # Calculate percentages\n    result = counts.join(totals, on=\"TRT01P\").with_columns([\n        (100.0 * pl.col(\"len\") / pl.col(\"total\")).round(1).alias(\"pct\")\n    ])\n\n    return result\n\nsex_stats = summarize_categorical(adsl, \"SEX\")\nsex_stats\n\n\nshape: (6, 5)\n\n\n\nTRT01P\nSEX\nlen\ntotal\npct\n\n\nstr\nstr\nu32\nu32\nf64\n\n\n\n\n\"Xanomeline High Dose\"\n\"Female\"\n40\n84\n47.6\n\n\n\"Placebo\"\n\"Female\"\n53\n86\n61.6\n\n\n\"Xanomeline High Dose\"\n\"Male\"\n44\n84\n52.4\n\n\n\"Xanomeline Low Dose\"\n\"Female\"\n50\n84\n59.5\n\n\n\"Xanomeline Low Dose\"\n\"Male\"\n34\n84\n40.5\n\n\n\"Placebo\"\n\"Male\"\n33\n86\n38.4\n\n\n\n\n\n\n\nrace_stats = summarize_categorical(adsl, \"RACE\")\nrace_stats\n\n\nshape: (7, 5)\n\n\n\nTRT01P\nRACE\nlen\ntotal\npct\n\n\nstr\nstr\nu32\nu32\nf64\n\n\n\n\n\"Xanomeline High Dose\"\n\"American Indian Or Alaska Nati…\n1\n84\n1.2\n\n\n\"Xanomeline Low Dose\"\n\"Black Or African American\"\n6\n84\n7.1\n\n\n\"Xanomeline High Dose\"\n\"White\"\n74\n84\n88.1\n\n\n\"Placebo\"\n\"Black Or African American\"\n8\n86\n9.3\n\n\n\"Placebo\"\n\"White\"\n78\n86\n90.7\n\n\n\"Xanomeline Low Dose\"\n\"White\"\n78\n84\n92.9\n\n\n\"Xanomeline High Dose\"\n\"Black Or African American\"\n9\n84\n10.7",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Baseline characteristics</span>"
    ]
  },
  {
    "objectID": "tlf-baseline.html#step-3-format-results",
    "href": "tlf-baseline.html#step-3-format-results",
    "title": "7  Baseline characteristics",
    "section": "7.4 Step 3: Format Results",
    "text": "7.4 Step 3: Format Results\nNow we format the statistics into the standard baseline table format.\n\n7.4.1 Format Age Statistics\n\n# Format age as \"Mean (SD)\" and \"Median [Min, Max]\"\nage_formatted = age_stats.with_columns([\n    pl.format(\"{} ({})\", pl.col(\"mean\"), pl.col(\"sd\")).alias(\"mean_sd\"),\n    pl.format(\"{} [{}, {}]\", pl.col(\"median\"), pl.col(\"min\"), pl.col(\"max\")).alias(\"median_range\")\n]).select([\"TRT01P\", \"mean_sd\", \"median_range\"])\n\nage_formatted\n\n\nshape: (3, 3)\n\n\n\nTRT01P\nmean_sd\nmedian_range\n\n\nstr\nstr\nstr\n\n\n\n\n\"Placebo\"\n\"75.2 (8.59)\"\n\"76.0 [52.0, 89.0]\"\n\n\n\"Xanomeline Low Dose\"\n\"75.7 (8.29)\"\n\"77.5 [51.0, 88.0]\"\n\n\n\"Xanomeline High Dose\"\n\"74.4 (7.89)\"\n\"76.0 [56.0, 88.0]\"\n\n\n\n\n\n\n\n\n7.4.2 Format Categorical Statistics\n\n# Format categorical as \"n (%)\"\nsex_formatted = sex_stats.with_columns(\n    pl.format(\"{} ({}%)\", pl.col(\"len\"), pl.col(\"pct\")).alias(\"n_pct\")\n).select([\"TRT01P\", \"SEX\", \"n_pct\"])\n\nrace_formatted = race_stats.with_columns(\n    pl.format(\"{} ({}%)\", pl.col(\"len\"), pl.col(\"pct\")).alias(\"n_pct\")\n).select([\"TRT01P\", \"RACE\", \"n_pct\"])\n\nsex_formatted\n\n\nshape: (6, 3)\n\n\n\nTRT01P\nSEX\nn_pct\n\n\nstr\nstr\nstr\n\n\n\n\n\"Xanomeline High Dose\"\n\"Female\"\n\"40 (47.6%)\"\n\n\n\"Placebo\"\n\"Female\"\n\"53 (61.6%)\"\n\n\n\"Xanomeline High Dose\"\n\"Male\"\n\"44 (52.4%)\"\n\n\n\"Xanomeline Low Dose\"\n\"Female\"\n\"50 (59.5%)\"\n\n\n\"Xanomeline Low Dose\"\n\"Male\"\n\"34 (40.5%)\"\n\n\n\"Placebo\"\n\"Male\"\n\"33 (38.4%)\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Baseline characteristics</span>"
    ]
  },
  {
    "objectID": "tlf-baseline.html#step-4-create-table-structure",
    "href": "tlf-baseline.html#step-4-create-table-structure",
    "title": "7  Baseline characteristics",
    "section": "7.5 Step 4: Create Table Structure",
    "text": "7.5 Step 4: Create Table Structure\nWe’ll build the table row by row following the standard baseline table format.\n\n# Helper function to get value for a treatment group\ndef get_value(df, treatment):\n    \"\"\"Get value for a specific treatment group or return default\"\"\"\n    result = df.filter(pl.col(\"TRT01P\") == treatment)\n    return result[result.columns[-1]][0] if result.height &gt; 0 else \"0 (0.0%)\"\n\n# Build the baseline table structure\ntable_rows = []\n\n# Age section\ntable_rows.append([\"Age (years)\", \"\", \"\", \"\"])\n\n# Age Mean (SD) row\nage_mean_row = [\"  Mean (SD)\"] + [\n    get_value(age_formatted.select([\"TRT01P\", \"mean_sd\"]), trt).replace(\"0 (0.0%)\", \"\")\n    for trt in [\"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]\n]\ntable_rows.append(age_mean_row)\n\n# Age Median [Min, Max] row\nage_median_row = [\"  Median [Min, Max]\"] + [\n    get_value(age_formatted.select([\"TRT01P\", \"median_range\"]), trt).replace(\"0 (0.0%)\", \"\")\n    for trt in [\"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]\n]\ntable_rows.append(age_median_row)\n\n# Sex section\ntable_rows.append([\"Sex\", \"\", \"\", \"\"])\n\nfor sex_cat in [\"Female\", \"Male\"]:\n    sex_data = sex_formatted.filter(pl.col(\"SEX\") == sex_cat)\n    sex_row = [f\"  {sex_cat}\"] + [\n        get_value(sex_data, trt)\n        for trt in [\"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]\n    ]\n    table_rows.append(sex_row)\n\n# Race section\ntable_rows.append([\"Race\", \"\", \"\", \"\"])\n\nfor race_cat in [\"White\", \"Black Or African American\", \"American Indian Or Alaska Native\"]:\n    race_data = race_formatted.filter(pl.col(\"RACE\") == race_cat)\n    race_row = [f\"  {race_cat}\"] + [\n        get_value(race_data, trt)\n        for trt in [\"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]\n    ]\n    table_rows.append(race_row)\n\n# Create DataFrame from table rows\nbaseline_table = pl.DataFrame(\n    table_rows,\n    schema=[\"Characteristic\", \"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"],\n    orient=\"row\"\n)\n\nbaseline_table\n\n\nshape: (10, 4)\n\n\n\nCharacteristic\nPlacebo\nXanomeline Low Dose\nXanomeline High Dose\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"Age (years)\"\n\"\"\n\"\"\n\"\"\n\n\n\"  Mean (SD)\"\n\"75.2 (8.59)\"\n\"75.7 (8.29)\"\n\"74.4 (7.89)\"\n\n\n\"  Median [Min, Max]\"\n\"76.0 [52.0, 89.0]\"\n\"77.5 [51.0, 88.0]\"\n\"76.0 [56.0, 88.0]\"\n\n\n\"Sex\"\n\"\"\n\"\"\n\"\"\n\n\n\"  Female\"\n\"53 (61.6%)\"\n\"50 (59.5%)\"\n\"40 (47.6%)\"\n\n\n\"  Male\"\n\"33 (38.4%)\"\n\"34 (40.5%)\"\n\"44 (52.4%)\"\n\n\n\"Race\"\n\"\"\n\"\"\n\"\"\n\n\n\"  White\"\n\"78 (90.7%)\"\n\"78 (92.9%)\"\n\"74 (88.1%)\"\n\n\n\"  Black Or African American\"\n\"8 (9.3%)\"\n\"6 (7.1%)\"\n\"9 (10.7%)\"\n\n\n\"  American Indian Or Alaska Na…\n\"0 (0.0%)\"\n\"0 (0.0%)\"\n\"1 (1.2%)\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Baseline characteristics</span>"
    ]
  },
  {
    "objectID": "tlf-baseline.html#step-5-generate-publication-ready-output",
    "href": "tlf-baseline.html#step-5-generate-publication-ready-output",
    "title": "7  Baseline characteristics",
    "section": "7.6 Step 5: Generate Publication-Ready Output",
    "text": "7.6 Step 5: Generate Publication-Ready Output\nFinally, we format the baseline table for regulatory submission using the rtflite package.\n\n# Get treatment group sizes for column headers\ntreatment_n = adsl.group_by(\"TRT01P\").len().sort(\"TRT01P\")\nn_placebo = treatment_n.filter(pl.col(\"TRT01P\") == \"Placebo\")[\"len\"][0]\nn_low = treatment_n.filter(pl.col(\"TRT01P\") == \"Xanomeline Low Dose\")[\"len\"][0]\nn_high = treatment_n.filter(pl.col(\"TRT01P\") == \"Xanomeline High Dose\")[\"len\"][0]\n\ndoc_baseline = rtf.RTFDocument(\n    df=baseline_table,\n    rtf_title=rtf.RTFTitle(\n        text=[\n            \"Baseline Characteristics of Participants\", \n            \"(All Participants Randomized)\"\n        ]\n    ),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\n            \"Characteristic\",\n            f\"Placebo\\n(N={n_placebo})\",\n            f\"Xanomeline Low Dose\\n(N={n_low})\",\n            f\"Xanomeline High Dose\\n(N={n_high})\"\n        ],\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n        col_rel_width=[3, 2, 2, 2]\n    ),\n    rtf_body=rtf.RTFBody(\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n        col_rel_width=[3, 2, 2, 2]\n    ),\n    rtf_source=rtf.RTFSource(text=[\"Source: ADSL dataset\"])\n)\n\ndoc_baseline.write_rtf(\"rtf/tlf_baseline.rtf\") # Save as RTF for submission\n\nrtf/tlf_baseline.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Baseline characteristics</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html",
    "href": "tlf-ae-summary.html",
    "title": "8  Adverse events summary",
    "section": "",
    "text": "8.1 Overview\nAdverse events (AE) summary tables are critical safety assessments required in clinical study reports. Following ICH E3 guidance, these tables summarize the overall safety profile by showing the number and percentage of participants experiencing various categories of adverse events across treatment groups.\nKey categories typically include:\nThis tutorial shows you how to create an AE summary table using Python’s rtflite package.\nimport polars as pl\nimport rtflite as rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#overview",
    "href": "tlf-ae-summary.html#overview",
    "title": "8  Adverse events summary",
    "section": "",
    "text": "Any adverse event: Total participants with at least one AE\nDrug-related events: Events potentially related to study treatment\nSerious adverse events: Events meeting regulatory criteria for seriousness\nDeaths: Fatal outcomes\nDiscontinuations: Participants who stopped treatment due to AEs",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#step-1-load-data",
    "href": "tlf-ae-summary.html#step-1-load-data",
    "title": "8  Adverse events summary",
    "section": "8.2 Step 1: Load Data",
    "text": "8.2 Step 1: Load Data\nWe need two datasets for AE analysis: the subject-level dataset (ADSL) and the adverse events dataset (ADAE).\n\n# Load datasets\nadsl = pl.read_parquet(\"data/adsl.parquet\")\nadae = pl.read_parquet(\"data/adae.parquet\")\n\n# Display key variables from ADSL\nadsl.select([\"USUBJID\", \"TRT01A\", \"SAFFL\"]).head()\n\n\nshape: (5, 3)\n\n\n\nUSUBJID\nTRT01A\nSAFFL\n\n\nstr\nstr\nstr\n\n\n\n\n\"01-701-1015\"\n\"Placebo\"\n\"Y\"\n\n\n\"01-701-1023\"\n\"Placebo\"\n\"Y\"\n\n\n\"01-701-1028\"\n\"Xanomeline High Dose\"\n\"Y\"\n\n\n\"01-701-1033\"\n\"Xanomeline Low Dose\"\n\"Y\"\n\n\n\"01-701-1034\"\n\"Xanomeline High Dose\"\n\"Y\"\n\n\n\n\n\n\n\n# Display key variables from ADAE\nadae.select([\"USUBJID\", \"AEREL\", \"AESER\", \"AEOUT\", \"AEACN\"]).head()\n\n\nshape: (5, 5)\n\n\n\nUSUBJID\nAEREL\nAESER\nAEOUT\nAEACN\n\n\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"01-701-1015\"\n\"PROBABLE\"\n\"N\"\n\"NOT RECOVERED/NOT RESOLVED\"\n\"\"\n\n\n\"01-701-1015\"\n\"PROBABLE\"\n\"N\"\n\"NOT RECOVERED/NOT RESOLVED\"\n\"\"\n\n\n\"01-701-1015\"\n\"REMOTE\"\n\"N\"\n\"RECOVERED/RESOLVED\"\n\"\"\n\n\n\"01-701-1023\"\n\"POSSIBLE\"\n\"N\"\n\"NOT RECOVERED/NOT RESOLVED\"\n\"\"\n\n\n\"01-701-1023\"\n\"PROBABLE\"\n\"N\"\n\"NOT RECOVERED/NOT RESOLVED\"\n\"\"\n\n\n\n\n\n\nKey ADAE variables used in this analysis:\n\nUSUBJID: Unique subject identifier to link with ADSL\nAEREL: Relationship of adverse event to study drug (e.g., “RELATED”, “POSSIBLE”, “PROBABLE”, “DEFINITE”, “NOT RELATED”)\nAESER: Serious adverse event flag (“Y” = serious, “N” = not serious)\nAEOUT: Outcome of adverse event (e.g., “RECOVERED”, “RECOVERING”, “NOT RECOVERED”, “FATAL”)\nAEACN: Action taken with study treatment (e.g., “DOSE NOT CHANGED”, “DRUG WITHDRAWN”, “DOSE REDUCED”)",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#step-2-filter-safety-population",
    "href": "tlf-ae-summary.html#step-2-filter-safety-population",
    "title": "8  Adverse events summary",
    "section": "8.3 Step 2: Filter Safety Population",
    "text": "8.3 Step 2: Filter Safety Population\nFor safety analyses, we focus on participants who received at least one dose of study treatment.\n\n# Filter to safety population\nadsl_safety = adsl.filter(pl.col(\"SAFFL\") == \"Y\").select([\"USUBJID\", \"TRT01A\"])\n\n# Get treatment counts for denominators\npop_counts = adsl_safety.group_by(\"TRT01A\").agg(\n    N = pl.len()\n).sort(\"TRT01A\")\n\n# Preserve the treatment level order for downstream joins\ntreatment_levels = pop_counts.select([\"TRT01A\"])\n\n# Safety population by treatment\npop_counts\n\n\nshape: (3, 2)\n\n\n\nTRT01A\nN\n\n\nstr\nu32\n\n\n\n\n\"Placebo\"\n86\n\n\n\"Xanomeline High Dose\"\n84\n\n\n\"Xanomeline Low Dose\"\n84\n\n\n\n\n\n\n\n# Join treatment information to AE data\nadae_safety = adae.join(adsl_safety, on=\"USUBJID\")\n\n# Total AE records in safety population\nadae_safety.height\n\n1191",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#step-3-define-ae-categories",
    "href": "tlf-ae-summary.html#step-3-define-ae-categories",
    "title": "8  Adverse events summary",
    "section": "8.4 Step 3: Define AE Categories",
    "text": "8.4 Step 3: Define AE Categories\nWe’ll calculate participant counts for standard AE categories used in regulatory submissions.\n\ndef count_participants(df, condition=None):\n    \"\"\"\n    Count unique participants meeting a condition\n\n    Args:\n        df: DataFrame with adverse events\n        condition: polars expression for filtering (None = count all)\n\n    Returns:\n        DataFrame with counts by treatment\n    \"\"\"\n    if condition is not None:\n        df = df.filter(condition)\n\n    counts = df.group_by(\"TRT01A\").agg(\n        n = pl.col(\"USUBJID\").n_unique()\n    )\n\n    return treatment_levels.join(counts, on=\"TRT01A\", how=\"left\").with_columns(\n        pl.col(\"n\").fill_null(0)\n    )\n\n# Calculate each category\ncategories = []\n\n# 1. Participants in population (no filtering)\npop_row = pop_counts.with_columns(\n    category = pl.lit(\"Participants in population\")\n).rename({\"N\": \"n\"})\ncategories.append(pop_row)\n\n# 2. With any adverse event\nany_ae = count_participants(adae_safety).with_columns(\n    category = pl.lit(\"With any adverse event\")\n)\ncategories.append(any_ae)\n\n\n# 3. With drug-related adverse event\ndrug_related = count_participants(\n    adae_safety,\n    pl.col(\"AEREL\").is_in([\"POSSIBLE\", \"PROBABLE\", \"DEFINITE\", \"RELATED\"])\n).with_columns(\n    category = pl.lit(\"With drug-related adverse event\")\n)\ncategories.append(drug_related)\n\n# 4. With serious adverse event\nserious = count_participants(\n    adae_safety,\n    pl.col(\"AESER\") == \"Y\"\n).with_columns(\n    category = pl.lit(\"With serious adverse event\")\n)\ncategories.append(serious)\n\n\n# 5. With serious drug-related adverse event\nserious_drug_related = count_participants(\n    adae_safety,\n    (pl.col(\"AESER\") == \"Y\") &\n    pl.col(\"AEREL\").is_in([\"POSSIBLE\", \"PROBABLE\", \"DEFINITE\", \"RELATED\"])\n).with_columns(\n    category = pl.lit(\"With serious drug-related adverse event\")\n)\ncategories.append(serious_drug_related)\n\n# 6. Who died\ndeaths = count_participants(\n    adae_safety,\n    pl.col(\"AEOUT\") == \"FATAL\"\n).with_columns(\n    category = pl.lit(\"Who died\")\n)\ncategories.append(deaths)\n\n# 7. Discontinued due to adverse event\ndiscontinued = count_participants(\n    adae_safety,\n    pl.col(\"AEACN\") == \"DRUG WITHDRAWN\"\n).with_columns(\n    category = pl.lit(\"Discontinued due to adverse event\")\n)\ncategories.append(discontinued)",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#step-4-combine-and-calculate-percentages",
    "href": "tlf-ae-summary.html#step-4-combine-and-calculate-percentages",
    "title": "8  Adverse events summary",
    "section": "8.5 Step 4: Combine and Calculate Percentages",
    "text": "8.5 Step 4: Combine and Calculate Percentages\nNow we combine all categories and calculate percentages based on the safety population.\n\n# Combine all categories\nae_summary = pl.concat(categories, how=\"diagonal\")\n\n# Add population totals and calculate percentages\nae_summary = ae_summary.join(\n    pop_counts.select([\"TRT01A\", \"N\"]),\n    on=\"TRT01A\",\n    how=\"left\"\n).with_columns([\n    # Fill missing counts with 0\n    pl.col(\"n\").fill_null(0),\n    # Calculate percentage\n    pl.when(pl.col(\"category\") == \"Participants in population\")\n        .then(None)  # No percentage for population row\n        .otherwise((100.0 * pl.col(\"n\") / pl.col(\"N\")).round(1))\n        .alias(\"pct\")\n])\n\nae_summary.sort([\"category\", \"TRT01A\"])\n\n\nshape: (21, 5)\n\n\n\nTRT01A\nn\ncategory\nN\npct\n\n\nstr\nu32\nstr\nu32\nf64\n\n\n\n\n\"Placebo\"\n0\n\"Discontinued due to adverse ev…\n86\n0.0\n\n\n\"Xanomeline High Dose\"\n0\n\"Discontinued due to adverse ev…\n84\n0.0\n\n\n\"Xanomeline Low Dose\"\n0\n\"Discontinued due to adverse ev…\n84\n0.0\n\n\n\"Placebo\"\n86\n\"Participants in population\"\n86\nnull\n\n\n\"Xanomeline High Dose\"\n84\n\"Participants in population\"\n84\nnull\n\n\n…\n…\n…\n…\n…\n\n\n\"Xanomeline High Dose\"\n2\n\"With serious adverse event\"\n84\n2.4\n\n\n\"Xanomeline Low Dose\"\n1\n\"With serious adverse event\"\n84\n1.2\n\n\n\"Placebo\"\n0\n\"With serious drug-related adve…\n86\n0.0\n\n\n\"Xanomeline High Dose\"\n1\n\"With serious drug-related adve…\n84\n1.2\n\n\n\"Xanomeline Low Dose\"\n1\n\"With serious drug-related adve…\n84\n1.2",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#step-5-format-for-display",
    "href": "tlf-ae-summary.html#step-5-format-for-display",
    "title": "8  Adverse events summary",
    "section": "8.6 Step 5: Format for Display",
    "text": "8.6 Step 5: Format for Display\nWe’ll format the counts and percentages for the final table display.\n\n# Format display values\nae_formatted = ae_summary.with_columns([\n    # Show counts as strings, including zeros\n    pl.col(\"n\").cast(str).alias(\"n_display\"),\n    # Format percentages with parentheses; blank out population row\n    pl.when(pl.col(\"category\") == \"Participants in population\")\n      .then(pl.lit(\"\"))\n      .otherwise(\n          pl.format(\"({})\", pl.col(\"pct\").fill_null(0).round(1).cast(str))\n      )\n      .alias(\"pct_display\")\n])\n\nae_formatted.select([\"category\", \"TRT01A\", \"n_display\", \"pct_display\"])\n\n\nshape: (21, 4)\n\n\n\ncategory\nTRT01A\nn_display\npct_display\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"Participants in population\"\n\"Placebo\"\n\"86\"\n\"\"\n\n\n\"Participants in population\"\n\"Xanomeline High Dose\"\n\"84\"\n\"\"\n\n\n\"Participants in population\"\n\"Xanomeline Low Dose\"\n\"84\"\n\"\"\n\n\n\"With any adverse event\"\n\"Placebo\"\n\"69\"\n\"(80.2)\"\n\n\n\"With any adverse event\"\n\"Xanomeline High Dose\"\n\"79\"\n\"(94.0)\"\n\n\n…\n…\n…\n…\n\n\n\"Who died\"\n\"Xanomeline High Dose\"\n\"0\"\n\"(0.0)\"\n\n\n\"Who died\"\n\"Xanomeline Low Dose\"\n\"1\"\n\"(1.2)\"\n\n\n\"Discontinued due to adverse ev…\n\"Placebo\"\n\"0\"\n\"(0.0)\"\n\n\n\"Discontinued due to adverse ev…\n\"Xanomeline High Dose\"\n\"0\"\n\"(0.0)\"\n\n\n\"Discontinued due to adverse ev…\n\"Xanomeline Low Dose\"\n\"0\"\n\"(0.0)\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#step-6-create-final-table-structure",
    "href": "tlf-ae-summary.html#step-6-create-final-table-structure",
    "title": "8  Adverse events summary",
    "section": "8.7 Step 6: Create Final Table Structure",
    "text": "8.7 Step 6: Create Final Table Structure\nWe reshape the data to create the final table with treatments as columns.\n\n# Define category order for consistent display\ncategory_order = [\n    \"Participants in population\",\n    \"With any adverse event\",\n    \"With drug-related adverse event\",\n    \"With serious adverse event\",\n    \"With serious drug-related adverse event\",\n    \"Who died\",\n    \"Discontinued due to adverse event\"\n]\n\n# Pivot to wide format\nae_wide = ae_formatted.pivot(\n    values=[\"n_display\", \"pct_display\"],\n    index=\"category\",\n    on=\"TRT01A\",\n    maintain_order=True\n)\n\n# Reorder columns for each treatment group\ntreatments = [\"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]\ncolumn_order = [\"category\"]\nfor trt in treatments:\n    column_order.extend([f\"n_display_{trt}\", f\"pct_display_{trt}\"])\n\n# Create final table with proper column order\nfinal_table = ae_wide.select(column_order).sort(\n    pl.col(\"category\").cast(pl.Enum(category_order))\n)\n\nfinal_table\n\n\nshape: (7, 7)\n\n\n\ncategory\nn_display_Placebo\npct_display_Placebo\nn_display_Xanomeline Low Dose\npct_display_Xanomeline Low Dose\nn_display_Xanomeline High Dose\npct_display_Xanomeline High Dose\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"Participants in population\"\n\"86\"\n\"\"\n\"84\"\n\"\"\n\"84\"\n\"\"\n\n\n\"With any adverse event\"\n\"69\"\n\"(80.2)\"\n\"77\"\n\"(91.7)\"\n\"79\"\n\"(94.0)\"\n\n\n\"With drug-related adverse even…\n\"44\"\n\"(51.2)\"\n\"73\"\n\"(86.9)\"\n\"70\"\n\"(83.3)\"\n\n\n\"With serious adverse event\"\n\"0\"\n\"(0.0)\"\n\"1\"\n\"(1.2)\"\n\"2\"\n\"(2.4)\"\n\n\n\"With serious drug-related adve…\n\"0\"\n\"(0.0)\"\n\"1\"\n\"(1.2)\"\n\"1\"\n\"(1.2)\"\n\n\n\"Who died\"\n\"2\"\n\"(2.3)\"\n\"1\"\n\"(1.2)\"\n\"0\"\n\"(0.0)\"\n\n\n\"Discontinued due to adverse ev…\n\"0\"\n\"(0.0)\"\n\"0\"\n\"(0.0)\"\n\"0\"\n\"(0.0)\"",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-summary.html#step-7-generate-publication-ready-output",
    "href": "tlf-ae-summary.html#step-7-generate-publication-ready-output",
    "title": "8  Adverse events summary",
    "section": "8.8 Step 7: Generate Publication-Ready Output",
    "text": "8.8 Step 7: Generate Publication-Ready Output\nFinally, we format the AE summary table for regulatory submission using the rtflite package.\n\n# Get population sizes for column headers\nn_placebo = pop_counts.filter(pl.col(\"TRT01A\") == \"Placebo\")[\"N\"][0]\nn_low = pop_counts.filter(pl.col(\"TRT01A\") == \"Xanomeline Low Dose\")[\"N\"][0]\nn_high = pop_counts.filter(pl.col(\"TRT01A\") == \"Xanomeline High Dose\")[\"N\"][0]\n\ndoc_ae_summary = rtf.RTFDocument(\n    df=final_table.rename({\"category\": \"\"}),\n    rtf_title=rtf.RTFTitle(\n        text=[\n            \"Analysis of Adverse Event Summary\",\n            \"(Safety Analysis Population)\"\n        ]\n    ),\n    rtf_column_header=[\n        rtf.RTFColumnHeader(\n            text = [\n                \"\",\n                \"Placebo\",\n                \"Xanomeline Low Dose\",\n                \"Xanomeline High Dose\"\n            ],\n            col_rel_width=[4, 2, 2, 2],\n            text_justification=[\"l\", \"c\", \"c\", \"c\"],\n        ),\n        rtf.RTFColumnHeader(\n            text=[\n                \"\",          # Empty for first column\n                \"n\", \"(%)\",  # Placebo columns\n                \"n\", \"(%)\",  # Low Dose columns\n                \"n\", \"(%)\"   # High Dose columns\n            ],\n            col_rel_width=[4] + [1] * 6,\n            text_justification=[\"l\"] + [\"c\"] * 6,\n            border_left = [\"single\"] + [\"single\", \"\"] * 3,\n            border_top = [\"\"] + [\"single\"] * 6\n        )\n    ],\n    rtf_body=rtf.RTFBody(\n        col_rel_width=[4] + [1] * 6,\n        text_justification=[\"l\"] + [\"c\"] * 6,\n        border_left = [\"single\"] + [\"single\", \"\"] * 3\n    ),\n    rtf_footnote=rtf.RTFFootnote(\n        text=[\n            \"Every subject is counted a single time for each applicable row and column.\"\n        ]\n    ),\n    rtf_source=rtf.RTFSource(\n        text=[\"Source: ADSL and ADAE datasets\"]\n    )\n)\n\ndoc_ae_summary.write_rtf(\"rtf/tlf_ae_summary.rtf\")\n\nrtf/tlf_ae_summary.rtf",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Adverse events summary</span>"
    ]
  },
  {
    "objectID": "tlf-ae-specific.html",
    "href": "tlf-ae-specific.html",
    "title": "9  Specific adverse events",
    "section": "",
    "text": "9.1 Setup\nThis article demonstrates how to create a specific adverse events table by System Organ Class and Preferred Term.\nimport polars as pl\nimport rtflite as rtf\n\nadsl = pl.read_parquet(\"data/adsl.parquet\")\nadae = pl.read_parquet(\"data/adae.parquet\")\ntreatments = [\"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Specific adverse events</span>"
    ]
  },
  {
    "objectID": "tlf-ae-specific.html#prepare-ae-summary-data",
    "href": "tlf-ae-specific.html#prepare-ae-summary-data",
    "title": "9  Specific adverse events",
    "section": "9.2 Prepare AE Summary Data",
    "text": "9.2 Prepare AE Summary Data\n\n# Get safety population counts and AE data\nadsl_safety = adsl.filter(pl.col(\"SAFFL\") == \"Y\").select([\"USUBJID\", \"TRT01A\"])\nadae_safety = adae.join(adsl_safety, on=\"USUBJID\", how=\"inner\")\npop_counts = adsl_safety.group_by(\"TRT01A\").agg(N=pl.len()).sort(\"TRT01A\")\n\n# Calculate AE counts by SOC and term\nae_counts = (\n    adae_safety.with_columns(pl.col(\"AEDECOD\").str.to_titlecase())\n    .group_by([\"TRT01A\", \"AEBODSYS\", \"AEDECOD\"])\n    .agg(n=pl.col(\"USUBJID\").n_unique())\n    .sort([\"AEBODSYS\", \"AEDECOD\", \"TRT01A\"])\n)\n\n# Build table rows\ntable_data = [\n    [\"Participants in population\"] + [str(pop_counts.filter(pl.col(\"TRT01A\") == t)[\"N\"][0]) for t in treatments],\n    [\"\"] * 4  # Blank row\n]\n\n# Add SOC and AE term rows\nfor soc in ae_counts[\"AEBODSYS\"].unique().sort():\n    table_data.append([soc] + [\"\"] * 3)\n    soc_data = ae_counts.filter(pl.col(\"AEBODSYS\") == soc)\n    \n    for ae in soc_data[\"AEDECOD\"].unique().sort():\n        row = [f\"  {ae}\"]\n        for trt in treatments:\n            count = soc_data.filter((pl.col(\"AEDECOD\") == ae) & (pl.col(\"TRT01A\") == trt))\n            row.append(str(count[\"n\"][0]) if count.height &gt; 0 else \"0\")\n        table_data.append(row)\n\ndf_ae_specific = pl.DataFrame(table_data, schema=[\"\"] + treatments, orient=\"row\")",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Specific adverse events</span>"
    ]
  },
  {
    "objectID": "tlf-ae-specific.html#create-rtf-output",
    "href": "tlf-ae-specific.html#create-rtf-output",
    "title": "9  Specific adverse events",
    "section": "9.3 Create RTF Output",
    "text": "9.3 Create RTF Output\n\ndoc_ae_specific = rtf.RTFDocument(\n    df=df_ae_specific,\n    rtf_title=rtf.RTFTitle(text=[\"Specific Adverse Events\", \"(Safety Analysis Population)\"]),\n    rtf_column_header=rtf.RTFColumnHeader(\n        text=[\"\", \"Placebo\\nn\", \"Xanomeline Low Dose\\nn\", \"Xanomeline High Dose\\nn\"],\n        col_rel_width=[4, 1, 1, 1],\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n    ),\n    rtf_body=rtf.RTFBody(\n        col_rel_width=[4, 1, 1, 1],\n        text_justification=[\"l\", \"c\", \"c\", \"c\"],\n        text_font_style=lambda df, i, j: \"bold\" if j == 0 and \"  \" not in str(df[i, j]) else \"\",\n    ),\n    rtf_footnote=rtf.RTFFootnote(text=[\"Number of participants with specific adverse events.\"]),\n    rtf_source=rtf.RTFSource(text=[\"Source: ADSL and ADAE datasets\"])\n)\n\ndoc_ae_specific.write_rtf(\"rtf/tlf_ae_specific.rtf\")\n\nrtf/tlf_ae_specific.rtf\n\n\n\n\nPosixPath('pdf/tlf_ae_specific.pdf')",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Specific adverse events</span>"
    ]
  },
  {
    "objectID": "tlf-efficacy-ancova.html",
    "href": "tlf-efficacy-ancova.html",
    "title": "10  ANCOVA efficacy analysis",
    "section": "",
    "text": "10.1 Setup\nThis article demonstrates how to create an ANCOVA efficacy table for glucose levels at Week 24 with LOCF imputation.\nimport polars as pl\nimport rtflite as rtf\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy import stats as scipy_stats\nfrom importlib.resources import files\n\nadsl = pl.read_parquet(\"data/adsl.parquet\")\nadlbc = pl.read_parquet(\"data/adlbc.parquet\")\ntreatments = [\"Placebo\", \"Xanomeline Low Dose\", \"Xanomeline High Dose\"]",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANCOVA efficacy analysis</span>"
    ]
  },
  {
    "objectID": "tlf-efficacy-ancova.html#prepare-analysis-data",
    "href": "tlf-efficacy-ancova.html#prepare-analysis-data",
    "title": "10  ANCOVA efficacy analysis",
    "section": "10.2 Prepare Analysis Data",
    "text": "10.2 Prepare Analysis Data\n\n# Clean data types and filter for efficacy population\nadlbc_clean = adlbc.with_columns(\n    [pl.col(c).cast(str).str.strip_chars() for c in [\"USUBJID\", \"PARAMCD\", \"AVISIT\", \"TRTP\"]]\n)\nadsl_eff = adsl.filter(pl.col(\"EFFFL\") == \"Y\").select([\"USUBJID\"])\nadlbc_eff = adlbc_clean.join(adsl_eff, on=\"USUBJID\", how=\"inner\")\n\n# Apply LOCF for glucose data up to Week 24\ngluc_data = (\n    adlbc_eff.filter((pl.col(\"PARAMCD\") == \"GLUC\") & (pl.col(\"AVISITN\") &lt;= 24))\n    .sort([\"USUBJID\", \"AVISITN\"])\n    .group_by(\"USUBJID\")\n    .agg([\n        pl.col(\"TRTP\").first(),\n        pl.col(\"BASE\").first(),\n        pl.col(\"AVAL\").filter(pl.col(\"AVISITN\") == 0).first().alias(\"Baseline\"),\n        pl.col(\"AVAL\").last().alias(\"Week 24\")\n    ])\n    .filter(pl.col(\"Baseline\").is_not_null() & pl.col(\"Week 24\").is_not_null())\n    .with_columns((pl.col(\"Week 24\") - pl.col(\"Baseline\")).alias(\"CHG\"))\n)\n\n# Calculate descriptive statistics\ndesc_stats = []\nfor trt in treatments:\n    trt_data = gluc_data.filter(pl.col(\"TRTP\") == trt)\n    baseline_full = adlbc_eff.filter(\n        (pl.col(\"PARAMCD\") == \"GLUC\") & (pl.col(\"AVISIT\") == \"Baseline\") & (pl.col(\"TRTP\") == trt)\n    )\n    \n    desc_stats.append({\n        \"Treatment\": trt,\n        \"N_Baseline\": baseline_full.height,\n        \"Baseline_Mean\": baseline_full[\"AVAL\"].mean() if baseline_full.height &gt; 0 else np.nan,\n        \"Baseline_SD\": baseline_full[\"AVAL\"].std() if baseline_full.height &gt; 0 else np.nan,\n        \"N_Week24\": trt_data.height,\n        \"Week24_Mean\": trt_data[\"Week 24\"].mean() if trt_data.height &gt; 0 else np.nan,\n        \"Week24_SD\": trt_data[\"Week 24\"].std() if trt_data.height &gt; 0 else np.nan,\n        \"N_Change\": trt_data.height,\n        \"Change_Mean\": trt_data[\"CHG\"].mean() if trt_data.height &gt; 0 else np.nan,\n        \"Change_SD\": trt_data[\"CHG\"].std() if trt_data.height &gt; 0 else np.nan\n    })\n\n# Perform ANCOVA\nancova_df = gluc_data.to_pandas()\nancova_df[\"TRTP\"] = pd.Categorical(ancova_df[\"TRTP\"], categories=treatments)\nmodel = smf.ols(\"CHG ~ TRTP + BASE\", data=ancova_df).fit()\n\n# Calculate LS means and confidence intervals\nbase_mean = ancova_df[\"BASE\"].mean()\nvar_cov = model.cov_params()\nls_means = []\n\nfor i, trt in enumerate(treatments):\n    x_pred = np.array([1, int(i==1), int(i==2), base_mean])\n    ls_mean = model.predict(pd.DataFrame({\"TRTP\": [trt], \"BASE\": [base_mean]}))[0]\n    se_pred = np.sqrt(x_pred @ var_cov @ x_pred.T)\n    \n    ls_means.append({\n        \"Treatment\": trt,\n        \"LS_Mean\": ls_mean,\n        \"CI_Lower\": ls_mean - 1.96 * se_pred,\n        \"CI_Upper\": ls_mean + 1.96 * se_pred\n    })",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANCOVA efficacy analysis</span>"
    ]
  },
  {
    "objectID": "tlf-efficacy-ancova.html#create-tables-for-rtf-output",
    "href": "tlf-efficacy-ancova.html#create-tables-for-rtf-output",
    "title": "10  ANCOVA efficacy analysis",
    "section": "10.3 Create Tables for RTF Output",
    "text": "10.3 Create Tables for RTF Output\n\n# Table 1: Descriptive Statistics\ntbl1_data = [\n    [\n        s[\"Treatment\"],\n        str(s[\"N_Baseline\"]),\n        f\"{s['Baseline_Mean']:.1f} ({s['Baseline_SD']:.2f})\",\n        str(s[\"N_Week24\"]),\n        f\"{s['Week24_Mean']:.1f} ({s['Week24_SD']:.2f})\",\n        str(s[\"N_Change\"]),\n        f\"{s['Change_Mean']:.1f} ({s['Change_SD']:.2f})\",\n        f\"{ls['LS_Mean']:.2f} ({ls['CI_Lower']:.2f}, {ls['CI_Upper']:.2f})\"\n    ]\n    for s, ls in zip(desc_stats, ls_means)\n]\n\ntbl1 = pl.DataFrame(tbl1_data, orient=\"row\", schema=[\n    \"Treatment\", \"N_Base\", \"Mean_SD_Base\", \"N_Wk24\", \"Mean_SD_Wk24\", \n    \"N_Chg\", \"Mean_SD_Chg\", \"LS_Mean_CI\"\n])\n\n# Table 2: Pairwise Comparisons\ntbl2_data = []\nfor comp_name, trt_name in [(\"Xanomeline Low Dose - Placebo\", \"TRTP[T.Xanomeline Low Dose]\"),\n                             (\"Xanomeline High Dose - Placebo\", \"TRTP[T.Xanomeline High Dose]\")] :\n    coef = model.params[trt_name]\n    se = model.bse[trt_name]\n    t_stat = coef / se\n    p_value = 2 * (1 - scipy_stats.t.cdf(abs(t_stat), model.df_resid))\n    \n    tbl2_data.append([\n        comp_name,\n        f\"{coef:.2f} ({coef - 1.96*se:.2f}, {coef + 1.96*se:.2f})\",\n        f\"{p_value:.3f}\"\n    ])\n\ntbl2 = pl.DataFrame(tbl2_data, orient=\"row\", schema=[\"Comparison\", \"Diff_CI\", \"P_Value\"])",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANCOVA efficacy analysis</span>"
    ]
  },
  {
    "objectID": "tlf-efficacy-ancova.html#create-rtf-document",
    "href": "tlf-efficacy-ancova.html#create-rtf-document",
    "title": "10  ANCOVA efficacy analysis",
    "section": "10.4 Create RTF Document",
    "text": "10.4 Create RTF Document\n\n# Create RTF document with two sections\ndoc_ancova = rtf.RTFDocument(\n    df=[tbl1, tbl2],\n    rtf_title=rtf.RTFTitle(text=[\n        \"ANCOVA of Change from Baseline Glucose (mmol/L) at Week 24\", \"LOCF\", \n        \"Efficacy Analysis Population\"\n    ]),\n    rtf_column_header=[\n        [rtf.RTFColumnHeader(text=[\"\", \"Baseline\", \"Week 24\", \"Change from Baseline\"],\n                           col_rel_width=[3, 2, 2, 4], text_justification=[\"l\", \"c\", \"c\", \"c\"]),\n         rtf.RTFColumnHeader(text=[\"Treatment\", \"N\", \"Mean (SD)\", \"N\", \"Mean (SD)\", \"N\", \n                                  \"Mean (SD)\", \"LS Mean (95% CI){^a}\"],\n                           col_rel_width=[3, 0.7, 1.3, 0.7, 1.3, 0.7, 1.3, 2],\n                           text_justification=[\"l\"] + [\"c\"] * 7, border_bottom=\"single\")],\n        [rtf.RTFColumnHeader(text=[\"Pairwise Comparison\", \"Difference in LS Mean (95% CI){^a}\", \"p-Value\"],\n                           col_rel_width=[5, 4, 2], text_justification=[\"l\", \"c\", \"c\"])]\n    ],\n    rtf_body=[\n        rtf.RTFBody(col_rel_width=[3, 0.7, 1.3, 0.7, 1.3, 0.7, 1.3, 2], \n                   text_justification=[\"l\"] + [\"c\"] * 7),\n        rtf.RTFBody(col_rel_width=[5, 4, 2], text_justification=[\"l\", \"c\", \"c\"])\n    ],\n    rtf_footnote=rtf.RTFFootnote(text=[\n        \"{^a}Based on an ANCOVA model after adjusting baseline value. LOCF approach is used to impute missing values.\",\n        \"ANCOVA = Analysis of Covariance, LOCF = Last Observation Carried Forward\",\n        \"CI = Confidence Interval, LS = Least Squares, SD = Standard Deviation\"\n    ]),\n    rtf_source=rtf.RTFSource(text=[\"Source: ADLBC dataset\"])\n)\n\ndoc_ancova.write_rtf(\"rtf/tlf_efficacy_ancova.rtf\")\n\nrtf/tlf_efficacy_ancova.rtf\n\n\n\n\nPosixPath('pdf/tlf_efficacy_ancova.pdf')",
    "crumbs": [
      "Clinical trial project",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANCOVA efficacy analysis</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wickham, Hadley, and Jennifer Bryan. 2023. R Packages. O’Reilly\nMedia, Inc.",
    "crumbs": [
      "References"
    ]
  }
]